{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-cYwFo",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-jde4s",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-cYwFo{œdataTypeœ:œPromptœ,œidœ:œPrompt-cYwFoœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-jde4s{œfieldNameœ:œinput_valueœ,œidœ:œAgent-jde4sœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-cYwFo",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-cYwFoœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-jde4s",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-jde4sœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DuckDuckGoSearchComponent",
            "id": "DuckDuckGoSearchComponent-D2Xm6",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-jde4s",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__DuckDuckGoSearchComponent-D2Xm6{œdataTypeœ:œDuckDuckGoSearchComponentœ,œidœ:œDuckDuckGoSearchComponent-D2Xm6œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-jde4s{œfieldNameœ:œtoolsœ,œidœ:œAgent-jde4sœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "DuckDuckGoSearchComponent-D2Xm6",
        "sourceHandle": "{œdataTypeœ:œDuckDuckGoSearchComponentœ,œidœ:œDuckDuckGoSearchComponent-D2Xm6œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-jde4s",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-jde4sœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-jde4s",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Prompt-IU7kz",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Agent-jde4s{œdataTypeœ:œAgentœ,œidœ:œAgent-jde4sœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-Prompt-IU7kz{œfieldNameœ:œinput_valueœ,œidœ:œPrompt-IU7kzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Agent-jde4s",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-jde4sœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-IU7kz",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPrompt-IU7kzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "WebSearchNoAPI",
            "id": "WebSearchNoAPI-pKAuU",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-gWor8",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__WebSearchNoAPI-pKAuU{œdataTypeœ:œWebSearchNoAPIœ,œidœ:œWebSearchNoAPI-pKAuUœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-gWor8{œfieldNameœ:œtoolsœ,œidœ:œAgent-gWor8œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "WebSearchNoAPI-pKAuU",
        "sourceHandle": "{œdataTypeœ:œWebSearchNoAPIœ,œidœ:œWebSearchNoAPI-pKAuUœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-gWor8",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-gWor8œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-gWor8",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-Hf4K1",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__Agent-gWor8{œdataTypeœ:œAgentœ,œidœ:œAgent-gWor8œ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-Hf4K1{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Hf4K1œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-gWor8",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-gWor8œ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-Hf4K1",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Hf4K1œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-cfvqx",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-gWor8",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Agent-cfvqx{œdataTypeœ:œAgentœ,œidœ:œAgent-cfvqxœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-Agent-gWor8{œfieldNameœ:œinput_valueœ,œidœ:œAgent-gWor8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Agent-cfvqx",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-cfvqxœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-gWor8",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-gWor8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-IU7kz",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-cfvqx",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-IU7kz{œdataTypeœ:œPromptœ,œidœ:œPrompt-IU7kzœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-cfvqx{œfieldNameœ:œinput_valueœ,œidœ:œAgent-cfvqxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-IU7kz",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-IU7kzœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-cfvqx",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-cfvqxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "oss-compass-api-tool",
            "id": "CustomComponent-hoy2H",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-jde4s",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-hoy2H{œdataTypeœ:œoss-compass-api-toolœ,œidœ:œCustomComponent-hoy2Hœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-jde4s{œfieldNameœ:œtoolsœ,œidœ:œAgent-jde4sœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-hoy2H",
        "sourceHandle": "{œdataTypeœ:œoss-compass-api-toolœ,œidœ:œCustomComponent-hoy2Hœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-jde4s",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-jde4sœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PythonPlotterComponent",
            "id": "PythonREPLComponent-9UuS0",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-gWor8",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__PythonREPLComponent-9UuS0{œdataTypeœ:œPythonPlotterComponentœ,œidœ:œPythonREPLComponent-9UuS0œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-gWor8{œfieldNameœ:œtoolsœ,œidœ:œAgent-gWor8œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "PythonREPLComponent-9UuS0",
        "sourceHandle": "{œdataTypeœ:œPythonPlotterComponentœ,œidœ:œPythonREPLComponent-9UuS0œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-gWor8",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-gWor8œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OllamaModel",
            "id": "OllamaModel-lVS64",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "agent_llm",
            "id": "Agent-WFHAK",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OllamaModel-lVS64{œdataTypeœ:œOllamaModelœ,œidœ:œOllamaModel-lVS64œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-Agent-WFHAK{œfieldNameœ:œagent_llmœ,œidœ:œAgent-WFHAKœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OllamaModel-lVS64",
        "sourceHandle": "{œdataTypeœ:œOllamaModelœ,œidœ:œOllamaModel-lVS64œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "Agent-WFHAK",
        "targetHandle": "{œfieldNameœ:œagent_llmœ,œidœ:œAgent-WFHAKœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "WebSearchNoAPI",
            "id": "WebSearchNoAPI-NEkgj",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-WFHAK",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-WebSearchNoAPI-NEkgj{œdataTypeœ:œWebSearchNoAPIœ,œidœ:œWebSearchNoAPI-NEkgjœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-WFHAK{œfieldNameœ:œtoolsœ,œidœ:œAgent-WFHAKœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "WebSearchNoAPI-NEkgj",
        "sourceHandle": "{œdataTypeœ:œWebSearchNoAPIœ,œidœ:œWebSearchNoAPI-NEkgjœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-WFHAK",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-WFHAKœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PythonPlotterComponent",
            "id": "PythonPlotterComponent-NEKFU",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-WFHAK",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-PythonPlotterComponent-NEKFU{œdataTypeœ:œPythonPlotterComponentœ,œidœ:œPythonPlotterComponent-NEKFUœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-WFHAK{œfieldNameœ:œtoolsœ,œidœ:œAgent-WFHAKœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "PythonPlotterComponent-NEKFU",
        "sourceHandle": "{œdataTypeœ:œPythonPlotterComponentœ,œidœ:œPythonPlotterComponent-NEKFUœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-WFHAK",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-WFHAKœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-WFHAK",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-BVMPU",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__Agent-WFHAK{œdataTypeœ:œAgentœ,œidœ:œAgent-WFHAKœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-BVMPU{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-BVMPUœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-WFHAK",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-WFHAKœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-BVMPU",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-BVMPUœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-UrdS9",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "DeepSeekModelComponent-UAUdL",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-UrdS9{œdataTypeœ:œPromptœ,œidœ:œPrompt-UrdS9œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-DeepSeekModelComponent-UAUdL{œfieldNameœ:œinput_valueœ,œidœ:œDeepSeekModelComponent-UAUdLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-UrdS9",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-UrdS9œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "DeepSeekModelComponent-UAUdL",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œDeepSeekModelComponent-UAUdLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DeepSeekModelComponent",
            "id": "DeepSeekModelComponent-UAUdL",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Prompt-YMFIw",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__DeepSeekModelComponent-UAUdL{œdataTypeœ:œDeepSeekModelComponentœ,œidœ:œDeepSeekModelComponent-UAUdLœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-YMFIw{œfieldNameœ:œinput_valueœ,œidœ:œPrompt-YMFIwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "DeepSeekModelComponent-UAUdL",
        "sourceHandle": "{œdataTypeœ:œDeepSeekModelComponentœ,œidœ:œDeepSeekModelComponent-UAUdLœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-YMFIw",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPrompt-YMFIwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-YMFIw",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "DeepSeekModelComponent-xlJ45",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-YMFIw{œdataTypeœ:œPromptœ,œidœ:œPrompt-YMFIwœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-DeepSeekModelComponent-xlJ45{œfieldNameœ:œinput_valueœ,œidœ:œDeepSeekModelComponent-xlJ45œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-YMFIw",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-YMFIwœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "DeepSeekModelComponent-xlJ45",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œDeepSeekModelComponent-xlJ45œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DeepSeekModelComponent",
            "id": "DeepSeekModelComponent-xlJ45",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Prompt-cYwFo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__DeepSeekModelComponent-xlJ45{œdataTypeœ:œDeepSeekModelComponentœ,œidœ:œDeepSeekModelComponent-xlJ45œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-cYwFo{œfieldNameœ:œinput_valueœ,œidœ:œPrompt-cYwFoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "DeepSeekModelComponent-xlJ45",
        "sourceHandle": "{œdataTypeœ:œDeepSeekModelComponentœ,œidœ:œDeepSeekModelComponent-xlJ45œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-cYwFo",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPrompt-cYwFoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DeepSeekModelComponent",
            "id": "DeepSeekModelComponent-oAhnt",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "agent_llm",
            "id": "Agent-jde4s",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__DeepSeekModelComponent-oAhnt{œdataTypeœ:œDeepSeekModelComponentœ,œidœ:œDeepSeekModelComponent-oAhntœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-Agent-jde4s{œfieldNameœ:œagent_llmœ,œidœ:œAgent-jde4sœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "DeepSeekModelComponent-oAhnt",
        "sourceHandle": "{œdataTypeœ:œDeepSeekModelComponentœ,œidœ:œDeepSeekModelComponent-oAhntœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "Agent-jde4s",
        "targetHandle": "{œfieldNameœ:œagent_llmœ,œidœ:œAgent-jde4sœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DeepSeekModelComponent",
            "id": "DeepSeekModelComponent-dM0pr",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "agent_llm",
            "id": "Agent-cfvqx",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__DeepSeekModelComponent-dM0pr{œdataTypeœ:œDeepSeekModelComponentœ,œidœ:œDeepSeekModelComponent-dM0prœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-Agent-cfvqx{œfieldNameœ:œagent_llmœ,œidœ:œAgent-cfvqxœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "DeepSeekModelComponent-dM0pr",
        "sourceHandle": "{œdataTypeœ:œDeepSeekModelComponentœ,œidœ:œDeepSeekModelComponent-dM0prœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "Agent-cfvqx",
        "targetHandle": "{œfieldNameœ:œagent_llmœ,œidœ:œAgent-cfvqxœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DeepSeekModelComponent",
            "id": "DeepSeekModelComponent-0Cvgn",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "agent_llm",
            "id": "Agent-gWor8",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__DeepSeekModelComponent-0Cvgn{œdataTypeœ:œDeepSeekModelComponentœ,œidœ:œDeepSeekModelComponent-0Cvgnœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-Agent-gWor8{œfieldNameœ:œagent_llmœ,œidœ:œAgent-gWor8œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "DeepSeekModelComponent-0Cvgn",
        "sourceHandle": "{œdataTypeœ:œDeepSeekModelComponentœ,œidœ:œDeepSeekModelComponent-0Cvgnœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "Agent-gWor8",
        "targetHandle": "{œfieldNameœ:œagent_llmœ,œidœ:œAgent-gWor8œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-gHJAA",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Prompt-UrdS9",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ChatInput-gHJAA{œdataTypeœ:œChatInputœ,œidœ:œChatInput-gHJAAœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-UrdS9{œfieldNameœ:œinput_valueœ,œidœ:œPrompt-UrdS9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-gHJAA",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-gHJAAœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-UrdS9",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPrompt-UrdS9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "note-QZWeT",
          "node": {
            "description": "# 📖 README\n举例：请为我分析openEuler社区的生态健康度\n[意图工程]\n1. 意图理解： 任务类型（查询/分析，这里要抽象些类型）、对象（openEuler）、维度/目标（社区生态健康度）\n2. 实体分析：openEuler是开源社区，包含哪些项目； 社区生态健康度定义；\n[知识工程]\n3. 目标分解：设计指标及模型（基于oss-compass知识库、搜索引擎），映射数据源、查询数据、启动数据获取、执行计算、返回结果\n[执行工程]\n4. 数据查询：openEuler社区数据（基于OSS-Compass API）\n5. 启动额外数据获取（可选）：基于OSS-Compass API、开放数据库API、搜索引擎等；\n6. 执行动态计算、返回结果\n7. 生成结构化结论和图表\n8. 用户反馈",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "id": "note-QZWeT",
        "measured": {
          "height": 588,
          "width": 325
        },
        "position": {
          "x": 794.4724762501945,
          "y": 1310.466471876714
        },
        "selected": false,
        "type": "noteNode"
      },
      {
        "data": {
          "id": "Prompt-UrdS9",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "input_value"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "input_value",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "你是一位顶级的开源项目分析师。你的任务是基于给定的定量数据和定性信息，生成一份专业、深入、图文并茂的分析报告。你必须严谨、客观，在不确定时，要主动使用工具进行核实。你的最终产出是一份可以直接发布的Markdown中文报告。"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "## 用户实际输入:\n{input_value}\n\n## 你的JSON输出:"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-UrdS9",
        "measured": {
          "height": 335,
          "width": 320
        },
        "position": {
          "x": 1490.2240059913308,
          "y": 1698.6424776026754
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DuckDuckGoSearchComponent-D2Xm6",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Search the web using DuckDuckGo with customizable result limits",
            "display_name": "DuckDuckGo Search",
            "documentation": "https://python.langchain.com/docs/integrations/tools/ddg",
            "edited": false,
            "field_order": [
              "input_value",
              "max_results",
              "max_snippet_length"
            ],
            "frozen": false,
            "icon": "DuckDuckGo",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_community.tools import DuckDuckGoSearchRun\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import IntInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\n\n\nclass DuckDuckGoSearchComponent(Component):\n    \"\"\"Component for performing web searches using DuckDuckGo.\"\"\"\n\n    display_name = \"DuckDuckGo Search\"\n    description = \"Search the web using DuckDuckGo with customizable result limits\"\n    documentation = \"https://python.langchain.com/docs/integrations/tools/ddg\"\n    icon = \"DuckDuckGo\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Search Query\",\n            required=True,\n            info=\"The search query to execute with DuckDuckGo\",\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            value=5,\n            required=False,\n            advanced=True,\n            info=\"Maximum number of search results to return\",\n        ),\n        IntInput(\n            name=\"max_snippet_length\",\n            display_name=\"Max Snippet Length\",\n            value=100,\n            required=False,\n            advanced=True,\n            info=\"Maximum length of each result snippet\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n    ]\n\n    def _build_wrapper(self) -> DuckDuckGoSearchRun:\n        \"\"\"Build the DuckDuckGo search wrapper.\"\"\"\n        return DuckDuckGoSearchRun()\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def fetch_content(self) -> list[Data]:\n        \"\"\"Execute the search and return results as Data objects.\"\"\"\n        try:\n            wrapper = self._build_wrapper()\n\n            full_results = wrapper.run(f\"{self.input_value} (site:*)\")\n\n            result_list = full_results.split(\"\\n\")[: self.max_results]\n\n            data_results = []\n            for result in result_list:\n                if result.strip():\n                    snippet = result[: self.max_snippet_length]\n                    data_results.append(\n                        Data(\n                            text=snippet,\n                            data={\n                                \"content\": result,\n                                \"snippet\": snippet,\n                            },\n                        )\n                    )\n        except (ValueError, AttributeError) as e:\n            error_data = [Data(text=str(e), data={\"error\": str(e)})]\n            self.status = error_data\n            return error_data\n        else:\n            self.status = data_results\n            return data_results\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        \"\"\"Convert the search results to a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the search results.\n        \"\"\"\n        data = self.fetch_content()\n        return DataFrame(data)\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "The search query to execute with DuckDuckGo",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Results",
                "dynamic": false,
                "info": "Maximum number of search results to return",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_snippet_length": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Snippet Length",
                "dynamic": false,
                "info": "Maximum length of each result snippet",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_snippet_length",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "input_value": {
                        "description": "The search query to execute with DuckDuckGo",
                        "title": "Input Value",
                        "type": "string"
                      }
                    },
                    "description": "Search the web using DuckDuckGo with customizable result limits",
                    "display_description": "Search the web using DuckDuckGo with customizable result limits",
                    "display_name": "fetch_content_dataframe",
                    "name": "fetch_content_dataframe",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "fetch_content_dataframe"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "DuckDuckGoSearchComponent"
        },
        "dragging": false,
        "id": "DuckDuckGoSearchComponent-D2Xm6",
        "measured": {
          "height": 217,
          "width": 320
        },
        "position": {
          "x": 3688.5691248536414,
          "y": 2219.9115291812177
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-YMFIw",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "input_value"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "input_value",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "## 输入的指令:\n{input_value}\n\n## 你的输出 (必须是包含任务清单的JSON):"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-YMFIw",
        "measured": {
          "height": 335,
          "width": 320
        },
        "position": {
          "x": 2340.7113468662947,
          "y": 1701.055118706875
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-cYwFo",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "input_value"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "input_value",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "## 任务规划:\n{input_value}\n\n使用工具完成你的任务\n\n## 你的JSON输出:"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-cYwFo",
        "measured": {
          "height": 365,
          "width": 320
        },
        "position": {
          "x": 3170.148575558027,
          "y": 1700.074064771959
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-jde4s",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Language Model",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "LanguageModel"
                ],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [
                  {
                    "icon": "Amazon"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "Azure"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Groq"
                  },
                  {
                    "icon": "NVIDIA"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "SambaNova"
                  },
                  {
                    "icon": "brain"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers.current_date import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.custom_component.component import _get_component_toolkit\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.field_typing import Tool\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n            # note the tools are not required to run the agent, hence the validation removed.\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v is not None}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = _get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\", tool_description=description, callbacks=self.get_langchain_callbacks()\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": true,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "input_types": [],
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Retrieve"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "input_types": [],
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "input_types": [],
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# 角色：数据获取调度员\n\n## 你的任务:\n你是一个智能的调度中心，负责执行一个包含多种任务的计划。你需要判断每个任务的类型，并调用最合适的工具来完成它。\n\n## 你的工具箱:\n1.  `oss-compass-api-tool`: FETCH_DATA用于执行`task_type`为 \"api\" 的任务，获取结构化的数字指标。\n2.  `DuckDuckGo Search`: FETCH_CONTENT_DATAFRAME用于执行`task_type`为 \"search\" 的任务，去网上查找定性信息。优先找时间最近和影响面最大的信息。\n\n## 规则:\n1.  仔细解析输入的任务规划JSON。\n2.  遍历`task_list`中的每一个任务对象。\n3.  自主决策：调用最合适的工具完成任务。\n4.  收集所有工具执行返回的结果，将它们汇总成一个清晰的、统一的JSON对象。\n\n## 任务规划:\n{input_value}\n\n## 你的JSON输出:\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-jde4s",
        "measured": {
          "height": 427,
          "width": 320
        },
        "position": {
          "x": 4133.6297332513695,
          "y": 1493.69495605895
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "WebSearchNoAPI-pKAuU",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Performs a basic DuckDuckGo search (HTML scraping). May be subject to rate limits.",
            "display_name": "Web Search",
            "documentation": "",
            "edited": false,
            "field_order": [
              "query",
              "timeout"
            ],
            "frozen": false,
            "icon": "search",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\nfrom urllib.parse import parse_qs, unquote, urlparse\n\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom langflow.custom import Component\nfrom langflow.io import IntInput, MessageTextInput, Output\nfrom langflow.schema import DataFrame\nfrom langflow.services.deps import get_settings_service\n\n\nclass WebSearchComponent(Component):\n    display_name = \"Web Search\"\n    description = \"Performs a basic DuckDuckGo search (HTML scraping). May be subject to rate limits.\"\n    icon = \"search\"\n    name = \"WebSearchNoAPI\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"Keywords to search for.\",\n            tool_mode=True,\n            required=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the web search request.\",\n            value=5,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"results\", display_name=\"Search Results\", method=\"perform_search\")]\n\n    def validate_url(self, string: str) -> bool:\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\" r\"(www\\.)?\" r\"([a-zA-Z0-9.-]+)\" r\"(\\.[a-zA-Z]{2,})?\" r\"(:\\d+)?\" r\"(\\/[^\\s]*)?$\",\n            re.IGNORECASE,\n        )\n        return bool(url_regex.match(string))\n\n    def ensure_url(self, url: str) -> str:\n        if not url.startswith((\"http://\", \"https://\")):\n            url = \"https://\" + url\n        if not self.validate_url(url):\n            msg = f\"Invalid URL: {url}\"\n            raise ValueError(msg)\n        return url\n\n    def _sanitize_query(self, query: str) -> str:\n        \"\"\"Sanitize search query.\"\"\"\n        # Remove potentially dangerous characters\n        return re.sub(r'[<>\"\\']', \"\", query.strip())\n\n    def perform_search(self) -> DataFrame:\n        query = self._sanitize_query(self.query)\n        if not query:\n            msg = \"Empty search query\"\n            raise ValueError(msg)\n        headers = {\"User-Agent\": get_settings_service().settings.user_agent}\n        params = {\"q\": query, \"kl\": \"us-en\"}\n        url = \"https://html.duckduckgo.com/html/\"\n\n        try:\n            response = requests.get(url, params=params, headers=headers, timeout=self.timeout)\n            response.raise_for_status()\n        except requests.RequestException as e:\n            self.status = f\"Failed request: {e!s}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"snippet\": str(e), \"content\": \"\"}]))\n\n        if not response.text or \"text/html\" not in response.headers.get(\"content-type\", \"\").lower():\n            self.status = \"No results found\"\n            return DataFrame(\n                pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"snippet\": \"No results found\", \"content\": \"\"}])\n            )\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        results = []\n\n        for result in soup.select(\"div.result\"):\n            title_tag = result.select_one(\"a.result__a\")\n            snippet_tag = result.select_one(\"a.result__snippet\")\n            if title_tag:\n                raw_link = title_tag.get(\"href\", \"\")\n                parsed = urlparse(raw_link)\n                uddg = parse_qs(parsed.query).get(\"uddg\", [\"\"])[0]\n                decoded_link = unquote(uddg) if uddg else raw_link\n\n                try:\n                    final_url = self.ensure_url(decoded_link)\n                    page = requests.get(final_url, headers=headers, timeout=self.timeout)\n                    page.raise_for_status()\n                    content = BeautifulSoup(page.text, \"lxml\").get_text(separator=\" \", strip=True)\n                except requests.RequestException as e:\n                    final_url = decoded_link\n                    content = f\"(Failed to fetch: {e!s}\"\n\n                results.append(\n                    {\n                        \"title\": title_tag.get_text(strip=True),\n                        \"link\": final_url,\n                        \"snippet\": snippet_tag.get_text(strip=True) if snippet_tag else \"\",\n                        \"content\": content,\n                    }\n                )\n\n        df_results = pd.DataFrame(results)\n        return DataFrame(df_results)\n"
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Keywords to search for.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "Timeout for the web search request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "query": {
                        "description": "Keywords to search for.",
                        "title": "Query",
                        "type": "string"
                      }
                    },
                    "description": "Performs a basic DuckDuckGo search (HTML scraping). May be subject to rate limits.",
                    "display_description": "Performs a basic DuckDuckGo search (HTML scraping). May be subject to rate limits.",
                    "display_name": "perform_search",
                    "name": "perform_search",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "perform_search"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "WebSearchNoAPI"
        },
        "dragging": false,
        "id": "WebSearchNoAPI-pKAuU",
        "measured": {
          "height": 217,
          "width": 320
        },
        "position": {
          "x": 5380.5543923269815,
          "y": 1967.7493941349264
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-hoy2H",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "通过OSS-Compass API获取指定仓库的贡献者里程碑画像数据。",
            "display_name": "oss-compass-api-tool",
            "documentation": "",
            "edited": true,
            "field_order": [
              "repo_url",
              "access_token"
            ],
            "frozen": false,
            "icon": "compass",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "access_token": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "OSS Compass Access Token",
                "dynamic": false,
                "info": "您的个人访问令牌。",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "access_token",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "oss-compass-api-key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# get_contributor_data.py\r\n\r\nimport requests\r\nimport json\r\nfrom datetime import datetime, timedelta\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema.data import Data\r\n\r\nclass GetContributorPersona(Component):\r\n    display_name = \"oss-compass-api-tool\"\r\n    description = \"通过OSS-Compass API获取指定仓库的贡献者里程碑画像数据。\"\r\n    icon = \"compass\"\r\n    name = \"oss-compass-api-tool\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"repo_url\",\r\n            display_name=\"仓库URL\",\r\n            info=\"需要分析的GitHub或Gitee仓库的完整URL。\",\r\n            required=True,\r\n            # 核心修正：将此字段标记为Agent调用的入口\r\n            tool_mode=True  \r\n        ),\r\n        MessageTextInput(\r\n            name=\"access_token\",\r\n            display_name=\"OSS Compass Access Token\",\r\n            info=\"您的个人访问令牌。\",\r\n            required=True,\r\n            # 注意：此字段是配置，而非Agent的直接输入，因此没有tool_mode\r\n        )\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"贡献者画像数据 (JSON)\",\r\n            name=\"persona_data\",\r\n            method=\"fetch_data\"\r\n        ),\r\n    ]\r\n\r\n    def fetch_data(self) -> Data:\r\n        # ... (此方法内部逻辑无需任何修改) ...\r\n        api_url = \"https://oss-compass.org/api/v2/metricModel/contributorMilestonePersona\"\r\n        end_date = datetime.now().strftime('%Y-%m-%d')\r\n        begin_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')\r\n        payload = {\r\n            \"access_token\": self.access_token, \"label\": self.repo_url,\r\n            \"begin_date\": begin_date, \"end_date\": end_date,\r\n            \"page\": \"1\", \"size\": \"1000\"\r\n        }\r\n        headers = {\"Content-Type\": \"application/json\"}\r\n        try:\r\n            response = requests.post(api_url, headers=headers, json=payload, timeout=60)\r\n            response.raise_for_status() \r\n            items = response.json().get('items', [])\r\n            return Data(value=json.dumps(items, indent=2, ensure_ascii=False))\r\n        except Exception as e:\r\n            return Data(value=json.dumps({\"error\": str(e)}))"
              },
              "repo_url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "仓库URL",
                "dynamic": false,
                "info": "需要分析的GitHub或Gitee仓库的完整URL。",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "repo_url",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://github.com/oss-compass/compass-web-service"
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "repo_url": {
                        "description": "需要分析的GitHub或Gitee仓库的完整URL。",
                        "title": "Repo Url",
                        "type": "string"
                      }
                    },
                    "description": "通过OSS-Compass API获取指定仓库的贡献者里程碑画像数据。",
                    "display_description": "通过OSS-Compass API获取指定仓库的贡献者里程碑画像数据。",
                    "display_name": "fetch_data",
                    "name": "fetch_data",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "fetch_data"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "oss-compass-api-tool"
        },
        "dragging": false,
        "id": "CustomComponent-hoy2H",
        "measured": {
          "height": 299,
          "width": 320
        },
        "position": {
          "x": 3687.9433254975556,
          "y": 1901.56268574531
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-15hpd",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "将Markdown文本和图表编译成PDF文件，并保存在服务器本地。",
            "display_name": "报告编译器",
            "documentation": "",
            "edited": true,
            "field_order": [
              "markdown_text",
              "plot_code",
              "plot_data_json",
              "output_filename"
            ],
            "frozen": false,
            "icon": "file-invoice",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# report_compiler.py\r\n\r\nimport os\r\nimport glob\r\nimport json\r\nimport pandas\r\nimport matplotlib\r\nimport seaborn\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output, FileInput\r\nfrom langflow.schema.message import Message\r\n\r\nclass ReportCompiler(Component):\r\n    display_name = \"报告编译器\"\r\n    description = \"将Markdown文本和图表编译成PDF文件，并保存在服务器本地。\"\r\n    icon = \"file-invoice\"\r\n    name = \"report_compiler\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"markdown_text\", display_name=\"Markdown报告文本\", required=True, tool_mode=True), # 核心修正\r\n        MessageTextInput(name=\"plot_code\", display_name=\"Python绘图代码\", required=True),\r\n        MessageTextInput(name=\"plot_data_json\", display_name=\"绘图数据JSON\", required=True),\r\n        MessageTextInput(name=\"output_filename\", display_name=\"输出PDF文件名\", value=\"community_health_report.pdf\"),\r\n    ]\r\n\r\n    outputs = [ Output(display_name=\"执行结果\", name=\"result\", method=\"compile_report\") ]\r\n\r\n    def compile_report(self) -> Message:\r\n        # ... (此方法内部逻辑无需任何修改) ...\r\n        from fpdf import FPDF # 移到方法内避免加载时检查\r\n        for old_chart in glob.glob(\"*.png\"): os.remove(old_chart)\r\n        execution_scope = {\r\n            'pd': pandas, 'sns': seaborn, 'plt': matplotlib.pyplot,\r\n            'json': json, 'plot_data_json_string': self.plot_data_json\r\n        }\r\n        try:\r\n            exec(self.plot_code, execution_scope)\r\n            generated_images = glob.glob(\"*.png\")\r\n        except Exception as e:\r\n            raise RuntimeError(f\"绘图代码执行失败: {e}\")\r\n\r\n        pdf = FPDF()\r\n        try:\r\n            pdf.add_font('NotoSansSC', '', 'NotoSansSC-Regular.otf', uni=True)\r\n            font_family = 'NotoSansSC'\r\n        except RuntimeError:\r\n            font_family = 'Arial'\r\n        \r\n        pdf.add_page()\r\n        pdf.set_font(font_family, size=12)\r\n        for line in self.markdown_text.split('\\n'):\r\n            pdf.multi_cell(0, 8, line)\r\n            pdf.ln(1)\r\n\r\n        for image_path in generated_images:\r\n            if os.path.exists(image_path):\r\n                pdf.add_page()\r\n                pdf.image(image_path, w=pdf.w - 20)\r\n        \r\n        try:\r\n            pdf.output(self.output_filename)\r\n            final_path = os.path.abspath(self.output_filename)\r\n            return Message(text=f\"报告已成功生成并保存至服务器路径: {final_path}\")\r\n        except Exception as e:\r\n            raise RuntimeError(f\"保存PDF文件时出错: {e}\")"
              },
              "markdown_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Markdown报告文本",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "markdown_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_filename": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "输出PDF文件名",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_filename",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "community_health_report.pdf"
              },
              "plot_code": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Python绘图代码",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "plot_code",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "plot_data_json": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "绘图数据JSON",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "plot_data_json",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "markdown_text": {
                        "description": "",
                        "title": "Markdown Text",
                        "type": "string"
                      }
                    },
                    "description": "将Markdown文本和图表编译成PDF文件，并保存在服务器本地。",
                    "display_description": "将Markdown文本和图表编译成PDF文件，并保存在服务器本地。",
                    "display_name": "compile_report",
                    "name": "compile_report",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "compile_report"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "report_compiler"
        },
        "dragging": false,
        "id": "CustomComponent-15hpd",
        "measured": {
          "height": 463,
          "width": 320
        },
        "position": {
          "x": 4799.1083330388965,
          "y": 2260.554677711729
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-cfvqx",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Language Model",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "LanguageModel"
                ],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [
                  {
                    "icon": "Amazon"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "Azure"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Groq"
                  },
                  {
                    "icon": "NVIDIA"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "SambaNova"
                  },
                  {
                    "icon": "brain"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers.current_date import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.custom_component.component import _get_component_toolkit\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.field_typing import Tool\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n            # note the tools are not required to run the agent, hence the validation removed.\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v is not None}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = _get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\", tool_description=description, callbacks=self.get_langchain_callbacks()\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": true,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "input_types": [],
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Retrieve"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "input_types": [],
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "input_types": [],
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# 角色: 数据提取与格式化专家\n\n## 你的任务:\n你接收一个包含多个贡献者画像对象的JSON数组。你的工作是：\n1.  遍历所有对象，找到`score`值最高的那一个。\n2.  提取出这个最高分对象的以下三个字段的值：\n    - `activity_casual_contributor_count`\n    - `activity_regular_contributor_count`\n    - `activity_core_contributor_count`\n3.  将这三个值格式化成一个用于制作条形图的、简洁的JSON数组。\n\n## 输入的原始数据 (示例):\n[\n  {\"uuid\": \"...\", \"score\": 85, \"activity_casual_contributor_count\": 10, \"activity_regular_contributor_count\": 5, \"activity_core_contributor_count\": 2},\n  {\"uuid\": \"...\", \"score\": 92, \"activity_casual_contributor_count\": 15, \"activity_regular_contributor_count\": 8, \"activity_core_contributor_count\": 4},\n  {\"uuid\": \"...\", \"score\": 88, \"activity_casual_contributor_count\": 12, \"activity_regular_contributor_count\": 6, \"activity_core_contributor_count\": 3}\n]\n\n## 你应该输出的格式化JSON (针对上面示例中score为92的对象):\n```json\n[\n  {\"contributor_type\": \"Casual\", \"count\": 15},\n  {\"contributor_type\": \"Regular\", \"count\": 8},\n  {\"contributor_type\": \"Core\", \"count\": 4}\n]"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-cfvqx",
        "measured": {
          "height": 427,
          "width": 320
        },
        "position": {
          "x": 5045.5923202721215,
          "y": 1516.3840012056596
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-IU7kz",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "input_value"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "input_value",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "\n## 原始数据:\n{input_value}\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-IU7kz",
        "measured": {
          "height": 319,
          "width": 320
        },
        "position": {
          "x": 4611.310896392035,
          "y": 1793.037352714456
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PythonREPLComponent-YUdUt",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Run Python code with optional imports. Use print() to see the output.",
            "display_name": "Python Interpreter",
            "documentation": "",
            "edited": false,
            "field_order": [
              "global_imports",
              "python_code"
            ],
            "frozen": false,
            "icon": "square-terminal",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Results",
                "group_outputs": false,
                "method": "run_python_repl",
                "name": "results",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import importlib\n\nfrom langchain_experimental.utilities import PythonREPL\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import CodeInput, Output, StrInput\nfrom langflow.schema.data import Data\n\n\nclass PythonREPLComponent(Component):\n    display_name = \"Python Interpreter\"\n    description = \"Run Python code with optional imports. Use print() to see the output.\"\n    icon = \"square-terminal\"\n\n    inputs = [\n        StrInput(\n            name=\"global_imports\",\n            display_name=\"Global Imports\",\n            info=\"A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.\",\n            value=\"math,pandas\",\n            required=True,\n        ),\n        CodeInput(\n            name=\"python_code\",\n            display_name=\"Python Code\",\n            info=\"The Python code to execute. Only modules specified in Global Imports can be used.\",\n            value=\"print('Hello, World!')\",\n            input_types=[\"Message\"],\n            tool_mode=True,\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Results\",\n            name=\"results\",\n            type_=Data,\n            method=\"run_python_repl\",\n        ),\n    ]\n\n    def get_globals(self, global_imports: str | list[str]) -> dict:\n        \"\"\"Create a globals dictionary with only the specified allowed imports.\"\"\"\n        global_dict = {}\n\n        try:\n            if isinstance(global_imports, str):\n                modules = [module.strip() for module in global_imports.split(\",\")]\n            elif isinstance(global_imports, list):\n                modules = global_imports\n            else:\n                msg = \"global_imports must be either a string or a list\"\n                raise TypeError(msg)\n\n            for module in modules:\n                try:\n                    imported_module = importlib.import_module(module)\n                    global_dict[imported_module.__name__] = imported_module\n                except ImportError as e:\n                    msg = f\"Could not import module {module}: {e!s}\"\n                    raise ImportError(msg) from e\n\n        except Exception as e:\n            self.log(f\"Error in global imports: {e!s}\")\n            raise\n        else:\n            self.log(f\"Successfully imported modules: {list(global_dict.keys())}\")\n            return global_dict\n\n    def run_python_repl(self) -> Data:\n        try:\n            globals_ = self.get_globals(self.global_imports)\n            python_repl = PythonREPL(_globals=globals_)\n            result = python_repl.run(self.python_code)\n            result = result.strip() if result else \"\"\n\n            self.log(\"Code execution completed successfully\")\n            return Data(data={\"result\": result})\n\n        except ImportError as e:\n            error_message = f\"Import Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except SyntaxError as e:\n            error_message = f\"Syntax Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except (NameError, TypeError, ValueError) as e:\n            error_message = f\"Error during execution: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n    def build(self):\n        return self.run_python_repl\n"
              },
              "global_imports": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Global Imports",
                "dynamic": false,
                "info": "A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "global_imports",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "math,pandas"
              },
              "python_code": {
                "_input_type": "CodeInput",
                "advanced": false,
                "display_name": "Python Code",
                "dynamic": false,
                "info": "The Python code to execute. Only modules specified in Global Imports can be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "python_code",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "type": "code",
                "value": "print('Hello, World!')"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PythonREPLComponent"
        },
        "id": "PythonREPLComponent-YUdUt",
        "measured": {
          "height": 307,
          "width": 320
        },
        "position": {
          "x": 2946.565438185036,
          "y": 2203.192030823427
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PythonREPLComponent-9UuS0",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
            "display_name": "Python Plotter (绘图版)",
            "documentation": "",
            "edited": true,
            "field_order": [
              "global_imports",
              "python_code"
            ],
            "frozen": false,
            "icon": "chart-line",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import base64\r\nimport importlib\r\nimport io\r\nimport traceback\r\n\r\n# 关键步骤：设置 matplotlib 使用 'Agg' 后端\r\n# 这必须在导入 pyplot 之前完成，以防止它尝试使用 GUI 后端\r\nimport matplotlib\r\nmatplotlib.use(\"Agg\")\r\n\r\nfrom langchain_experimental.utilities import PythonREPL\r\nfrom langflow.custom.custom_component.component import Component\r\nfrom langflow.io import CodeInput, Output, StrInput\r\nfrom langflow.schema.data import Data\r\n\r\n\r\nclass PythonPlotterComponent(Component):\r\n    \"\"\"\r\n    一个可以执行 Python 代码并生成数据可视化图表的组件。\r\n    \"\"\"\r\n    display_name = \"Python Plotter (绘图版)\"\r\n    description = \"执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。\"\r\n    icon = \"chart-line\"\r\n    beta = True\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"global_imports\",\r\n            display_name=\"依赖库导入\",\r\n            info=\"需要导入的 Python 库，用逗号分隔。支持别名，例如 'pandas as pd, matplotlib.pyplot as plt'。\",\r\n            value=\"pandas,matplotlib.pyplot as plt\", # 默认包含 pandas 和 matplotlib\r\n            required=True,\r\n        ),\r\n        CodeInput(\r\n            name=\"python_code\",\r\n            display_name=\"Python 代码\",\r\n            info=\"在此处编写用于数据处理和绘图的 Python 代码。组件会自动捕获生成的图表。\",\r\n            # 提供一个默认的、可直接运行的绘图示例\r\n            value=(\r\n                \"# 1. 创建一个 pandas DataFrame 作为示例数据\\n\"\r\n                \"data = {\\n\"\r\n                \"    '月份': ['一月', '二月', '三月', '四月', '五月'],\\n\"\r\n                \"    '销售额(万)': [23, 45, 55, 48, 62]\\n\"\r\n                \"}\\n\"\r\n                \"df = pandas.DataFrame(data)\\n\\n\"\r\n                \"# 2. 使用 DataFrame 的 plot 功能创建图表\\n\"\r\n                \"# 注意：不需要调用 plt.show()\\n\"\r\n                \"df.plot(x='月份', y='销售额(万)', kind='bar', title='月度销售额分析', legend=False)\\n\"\r\n                \"plt.ylabel('销售额 (万元)')\\n\"\r\n                \"plt.xticks(rotation=0)\\n\"\r\n                \"plt.grid(axis='y', linestyle='--')\\n\"\r\n            ),\r\n            input_types=[\"Message\"],\r\n            tool_mode=True,\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"图表输出\",\r\n            name=\"plot_image\",\r\n            method=\"run_and_plot\",\r\n            type_=Data,\r\n        ),\r\n        Output(\r\n            display_name=\"文本输出\",\r\n            name=\"text_result\",\r\n            method=\"run_and_plot\",\r\n            type_=Data,\r\n        )\r\n    ]\r\n\r\n    def get_globals(self, global_imports: str) -> dict:\r\n        \"\"\"\r\n        根据用户输入的字符串创建一个包含允许导入模块的全局字典。\r\n        增强版：支持 'as' 别名。\r\n        \"\"\"\r\n        global_dict = {}\r\n        modules = [module.strip() for module in global_imports.split(\",\") if module.strip()]\r\n\r\n        for module in modules:\r\n            try:\r\n                if \" as \" in module:\r\n                    module_name, alias = [part.strip() for part in module.split(\" as \")]\r\n                    imported_module = importlib.import_module(module_name)\r\n                    global_dict[alias] = imported_module\r\n                else:\r\n                    imported_module = importlib.import_module(module)\r\n                    global_dict[imported_module.__name__] = imported_module\r\n            except ImportError as e:\r\n                raise ImportError(f\"无法导入模块 '{module.split(' as ')[0]}': {e}\") from e\r\n\r\n        self.log(f\"成功导入模块: {list(global_dict.keys())}\")\r\n        return global_dict\r\n\r\n    def run_and_plot(self) -> list[Data]:\r\n        \"\"\"\r\n        执行用户代码，捕获标准输出和生成的图表。\r\n        \"\"\"\r\n        image_data = Data(data={})\r\n        text_data = Data(data={})\r\n        \r\n        # 必须在这里导入 pyplot，因为它依赖于之前设置的 'Agg' 后端\r\n        import matplotlib.pyplot as plt\r\n\r\n        try:\r\n            # 1. 设置安全的全局变量\r\n            globals_ = self.get_globals(self.global_imports)\r\n            globals_[\"plt\"] = plt # 确保 plt 始终可用\r\n            \r\n            # 2. 执行用户代码\r\n            python_repl = PythonREPL(_globals=globals_)\r\n            text_result = python_repl.run(self.python_code)\r\n            \r\n            # 3. 捕获图表\r\n            # 检查当前是否有活动的图表\r\n            if plt.get_fignums():\r\n                fig = plt.gcf() # Get current figure\r\n\r\n                # 将图表保存到内存缓冲区\r\n                buf = io.BytesIO()\r\n                fig.savefig(buf, format='png', bbox_inches='tight', dpi=150)\r\n                buf.seek(0)\r\n                \r\n                # 将图像编码为 Base64 字符串\r\n                image_base64 = base64.b64encode(buf.read()).decode('utf-8')\r\n                \r\n                # 将 Base64 字符串包装成 Data URI 格式，方便前端显示\r\n                plot_uri = f\"data:image/png;base64,{image_base64}\"\r\n                image_data = Data(data={\"plot\": plot_uri}, artifact_type=\"image\")\r\n                self.log(\"成功生成并捕获图表。\")\r\n\r\n            text_result = text_result.strip() if text_result else \"代码已执行，但没有文本输出。\"\r\n            text_data = Data(data={\"result\": text_result})\r\n            self.log(f\"代码执行的文本输出: {text_result}\")\r\n\r\n        except Exception as e:\r\n            error_message = f\"执行代码时出错: {e}\\n{traceback.format_exc()}\"\r\n            self.log(error_message, level=\"error\")\r\n            # 在两个输出中都报告错误\r\n            error_data = Data(data={\"error\": error_message})\r\n            return [error_data, error_data]\r\n        \r\n        finally:\r\n            # 4. 清理，关闭所有图表以释放内存，防止在多次运行时叠加\r\n            plt.close('all')\r\n\r\n        return [image_data, text_data]"
              },
              "global_imports": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "依赖库导入",
                "dynamic": false,
                "info": "需要导入的 Python 库，用逗号分隔。支持别名，例如 'pandas as pd, matplotlib.pyplot as plt'。",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "global_imports",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "math,pandas,matplotlib,seaborn"
              },
              "python_code": {
                "_input_type": "CodeInput",
                "advanced": false,
                "display_name": "Python 代码",
                "dynamic": false,
                "info": "在此处编写用于数据处理和绘图的 Python 代码。组件会自动捕获生成的图表。",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "python_code",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "type": "code",
                "value": "# 1. 创建一个 pandas DataFrame 作为示例数据\r\n# 在真实场景中，数据可能来自文件或数据库\r\ndata = {\r\n    '月份': ['一月', '二月', '三月', '四月', '五月', '六月'],\r\n    '销售额(万元)': [23, 45, 55, 48, 62, 85]\r\n}\r\ndf = pandas.DataFrame(data)\r\n\r\n# 打印 DataFrame，其输出会显示在“文本输出”中\r\nprint(\"生成的示例数据:\")\r\nprint(df)\r\n\r\n# 2. 使用 DataFrame 的 plot 功能创建图表\r\n#    kind='line' 表示折线图, marker='o' 使数据点更明显\r\ndf.plot(x='月份', y='销售额(万元)', kind='line', marker='o', legend=False)\r\n\r\n# 3. 使用 plt 的函数美化图表\r\n#    注意：不需要调用 plt.show()，组件会自动捕获图像\r\nplt.title('上半年销售额趋势分析')  # 添加图表标题\r\nplt.ylabel('销售额 (万元)')         # 设置 Y 轴标签\r\nplt.xlabel('月份')                 # 设置 X 轴标签\r\nplt.grid(True, linestyle='--', alpha=0.7) # 添加背景网格线，方便阅读\r\nplt.xticks(rotation=0)             # 保持 X 轴标签水平，防止倾斜\r\nplt.tight_layout()                 # 自动调整布局，防止标签重叠"
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "python_code": {
                        "description": "在此处编写用于数据处理和绘图的 Python 代码。组件会自动捕获生成的图表。",
                        "title": "Python Code",
                        "type": "string"
                      }
                    },
                    "description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
                    "display_description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
                    "display_name": "run_and_plot",
                    "name": "run_and_plot",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "run_and_plot"
                    ]
                  },
                  {
                    "args": {
                      "python_code": {
                        "description": "在此处编写用于数据处理和绘图的 Python 代码。组件会自动捕获生成的图表。",
                        "title": "Python Code",
                        "type": "string"
                      }
                    },
                    "description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
                    "display_description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
                    "display_name": "run_and_plot",
                    "name": "run_and_plot",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "run_and_plot"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "PythonPlotterComponent"
        },
        "dragging": false,
        "id": "PythonREPLComponent-9UuS0",
        "measured": {
          "height": 315,
          "width": 320
        },
        "position": {
          "x": 5376.222315728658,
          "y": 2253.90103176565
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-gWor8",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Language Model",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "LanguageModel"
                ],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [
                  {
                    "icon": "Amazon"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "Azure"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Groq"
                  },
                  {
                    "icon": "NVIDIA"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "SambaNova"
                  },
                  {
                    "icon": "brain"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers.current_date import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.custom_component.component import _get_component_toolkit\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.field_typing import Tool\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n            # note the tools are not required to run the agent, hence the validation removed.\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v is not None}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = _get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\", tool_description=description, callbacks=self.get_langchain_callbacks()\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": true,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "input_types": [],
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Retrieve"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "input_types": [],
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "input_types": [],
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# 角色: 数据分析师与报告撰写员\n\n## 你的最终目标\n\n根据我提供的一份包含定量和定性数据的JSON输入，生成一份图文并茂的、可直接渲染的Markdown中文分析报告。\n\n## 关键心法\n\n**你的世界里没有本地文件系统**。所有生成的数据，尤其是图表，都必须在内存中处理。图表通过`Base64`编码在工具间传递，并最终以`Data URI`的形式直接嵌入到最终的Markdown报告中，使其成为一个完全自包含的文档。**不要尝试保存或引用本地文件路径如 `chart.png`**。\n\n## 你的输入格式\n\n你将收到一个JSON对象，它包含两个键：\n\n1.  `quantitative_data`: 一个JSON数组，包含了需要进行可视化分析的量化数据。\n2.  `qualitative_data`: 一段文本，包含了通过初步搜索获得的定性信息摘要。\n\n## 你的工具箱\n\n你拥有以下两个强大的工具来帮助你完成任务：\n\n1.  **`python_plotter`**: RUN_AND_PLOT\n\n      - **功能**: 执行Python代码以进行数据分析和图表生成。重要的是，此工具会捕获代码的`print`输出，并将其作为包含`image_base64`键的JSON对象返回。\n      - **何时使用**: 当你需要对 `quantitative_data` 进行处理、计算，并生成可视化图表时。\n      - **如何使用 (核心指令)**: 你编写的Python代码**必须**遵循以下模板来生成并输出图表：\n        ```python\n        # 1. 导入必要的库\n        import pandas as pd\n        import matplotlib.pyplot as plt\n        import io\n        import base64\n        import json\n\n        # 2. 将输入数据（假设为json格式字符串）加载到DataFrame\n        # data_string = '''...''' # 你的输入数据\n        # df = pd.read_json(io.StringIO(data_string))\n\n        # 3. 编写你的数据处理和绘图逻辑\n        # 例如: df.plot(kind='bar')\n\n        # 4. (关键步骤) 将图表保存到内存缓冲区\n        buf = io.BytesIO()\n        plt.savefig(buf, format='png', bbox_inches='tight')\n        buf.seek(0)\n\n        # 5. (关键步骤) 将缓冲区中的图像编码为Base64字符串\n        image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n\n        # 6. (关键步骤) 将Base64字符串包装在JSON中打印输出\n        # 工具会捕获这个打印输出并将其作为结果返回给你\n        print(json.dumps({\"image_base64\": image_base64}))\n\n        # 清理图像，防止污染下一次绘图\n        plt.close()\n        ```\n      - **工具的返回值**: 你将收到一个JSON对象，例如：`{\"image_base64\": \"iVBORw0KGgoAAAANSUhEUgA...\"}`。\n\n2.  **`web_search`**: PERFORM_SEARCH\n\n      - **功能**: 在网络上搜索信息以补充或验证你的分析。\n      - **何时使用**: 当你需要对定性数据进行事实核查，或获取完成报告所需的额外背景信息时。\n      - **如何使用**: 提出一个精确的问题进行搜索。\n\n## 你的工作流程\n\n1.  **分析定量数据**: 查看 `quantitative_data`，构思最合适的图表来展示其内在关系或趋势。\n2.  **生成图表并获取编码**: 调用 `chart_generator` 工具，使用上述模板编写并执行Python代码。执行后，**接收并记住返回的JSON中的`image_base64`字符串**。\n3.  **分析定性数据**: 阅读 `qualitative_data`，理解其核心观点和洞察。\n4.  **事实核查与补充 (可选)**: 如果对定性信息有疑问或认为信息不足，调用 `web_search` 工具进行确认和补充。\n5.  **综合撰写报告**: 综合所有信息，撰写最终的Markdown报告。报告必须包含：\n      - **第一部分：定量信息可视化**: 对图表的解读。**必须**使用以下`Data URI`语法来嵌入你收到的Base64图表：\n        ```markdown\n        ![图表描述](data:image/png;base64,你从工具获取到的Base64字符串)\n        ```\n      - **第二部分：定性信息展示**: 对定性信息的总结、验证和深入分析。\n\n## 当前任务的输入数据:\n\n{input\\_value}"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-gWor8",
        "measured": {
          "height": 427,
          "width": 320
        },
        "position": {
          "x": 5814.017991233735,
          "y": 1516.7921964334214
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-Hf4K1",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([safe_convert(item, clean_data=self.clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-Hf4K1",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 6323.0888722864265,
          "y": 1991.9901223960044
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-5Y8Tg",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://github.com/oss-compass/compass-web-service 分析贡献者画像和社区影响力"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-5Y8Tg",
        "measured": {
          "height": 203,
          "width": 320
        },
        "position": {
          "x": 1191.9362904426457,
          "y": 1217.8994154905065
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "oss-compass-api-tool-QgaqG",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "通过OSS-Compass API获取指定仓库的贡献者里程碑画像数据。",
            "display_name": "oss-compass-api-tool",
            "documentation": "",
            "edited": true,
            "field_order": [
              "repo_url",
              "access_token"
            ],
            "frozen": false,
            "icon": "compass",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "贡献者画像数据 (JSON)",
                "group_outputs": false,
                "hidden": null,
                "method": "fetch_data",
                "name": "persona_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "access_token": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "OSS Compass Access Token",
                "dynamic": false,
                "info": "您的个人访问令牌。",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "access_token",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "oss-compass-api-key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# get_contributor_data.py\r\n\r\nimport requests\r\nimport json\r\nfrom datetime import datetime, timedelta\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema.data import Data\r\n\r\nclass GetContributorPersona(Component):\r\n    display_name = \"oss-compass-api-tool\"\r\n    description = \"通过OSS-Compass API获取指定仓库的贡献者里程碑画像数据。\"\r\n    icon = \"compass\"\r\n    name = \"oss-compass-api-tool\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"repo_url\",\r\n            display_name=\"仓库URL\",\r\n            info=\"需要分析的GitHub或Gitee仓库的完整URL。\",\r\n            required=True,\r\n            # 核心修正：将此字段标记为Agent调用的入口\r\n            tool_mode=True  \r\n        ),\r\n        MessageTextInput(\r\n            name=\"access_token\",\r\n            display_name=\"OSS Compass Access Token\",\r\n            info=\"您的个人访问令牌。\",\r\n            required=True,\r\n            # 注意：此字段是配置，而非Agent的直接输入，因此没有tool_mode\r\n        )\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"贡献者画像数据 (JSON)\",\r\n            name=\"persona_data\",\r\n            method=\"fetch_data\"\r\n        ),\r\n    ]\r\n\r\n    def fetch_data(self) -> Data:\r\n        # ... (此方法内部逻辑无需任何修改) ...\r\n        api_url = \"https://oss-compass.org/api/v2/metricModel/contributorMilestonePersona\"\r\n        end_date = datetime.now().strftime('%Y-%m-%d')\r\n        begin_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')\r\n        payload = {\r\n            \"access_token\": self.access_token, \"label\": self.repo_url,\r\n            \"begin_date\": begin_date, \"end_date\": end_date,\r\n            \"page\": \"1\", \"size\": \"1000\"\r\n        }\r\n        headers = {\"Content-Type\": \"application/json\"}\r\n        try:\r\n            response = requests.post(api_url, headers=headers, json=payload, timeout=60)\r\n            response.raise_for_status() \r\n            items = response.json().get('items', [])\r\n            return Data(value=json.dumps(items, indent=2, ensure_ascii=False))\r\n        except Exception as e:\r\n            return Data(value=json.dumps({\"error\": str(e)}))"
              },
              "repo_url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "仓库URL",
                "dynamic": false,
                "info": "需要分析的GitHub或Gitee仓库的完整URL。",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "repo_url",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://github.com/oss-compass/compass-web-service"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "oss-compass-api-tool"
        },
        "dragging": false,
        "id": "oss-compass-api-tool-QgaqG",
        "measured": {
          "height": 301,
          "width": 320
        },
        "position": {
          "x": 4277.368583341065,
          "y": 2339.092584489863
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-wEVqj",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Language Model",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "LanguageModel"
                ],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [
                  {
                    "icon": "Amazon"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "Azure"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Groq"
                  },
                  {
                    "icon": "NVIDIA"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "SambaNova"
                  },
                  {
                    "icon": "brain"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers.current_date import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.custom_component.component import _get_component_toolkit\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.field_typing import Tool\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n            # note the tools are not required to run the agent, hence the validation removed.\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v is not None}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = _get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\", tool_description=description, callbacks=self.get_langchain_callbacks()\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": true,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "input_types": [],
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Retrieve"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "input_types": [],
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "input_types": [],
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# 角色: 数据分析师与报告撰写员\n\n## 你的最终目标:\n根据我提供的一份包含定量和定性数据的JSON输入，生成一份图文并茂的Markdown中文分析报告。\n## 你的输入格式:\n你将收到一个JSON对象，它包含两个键：\n1.  `quantitative_data`: 一个JSON数组，包含了需要进行可视化分析的量化数据。\n2.  `qualitative_data`: 一段文本，包含了通过初步搜索获得的定性信息摘要。\n\n## 你的工具箱:\n你拥有以下两个强大的工具来帮助你完成任务：\n\n1.  **`python_code_interpreter`**: PERFORM_SEARCH\n    - **何时使用**: 当你需要对 `quantitative_data` 进行数据处理、计算或**生成可视化图表**时，使用此工具。\n    - **如何使用**: 编写Python代码（可使用pandas, matplotlib, seaborn库），代码必须将生成的图表保存到本地文件（例如 `plt.savefig('chart.png')`）。执行后，工具本身不返回图片，但你要知道图片已经生成。\n\n2.  **`web_search`**: RUN_PYTHON_REPL\n    - **何时使用**: 当你需要**补充**当前知识范围之外的最新信息时，使用此工具。这是保证报告准确性的关键。\n    - **如何使用**: 提出一个精确的问题进行搜索。\n\n## 你的工作流程:\n1.  **分析定量数据**: 查看 `quantitative_data`，构思如何通过图表来展示它。\n2.  **生成图表**: 调用 `python_code_interpreter` 工具，编写并执行Python代码，生成一张或多张图表，并将它们保存为 `.png` 文件。\n3.  **分析定性数据**: 阅读 `qualitative_data`，理解其核心观点。\n4.  **事实核查与补充**: 如果对定性信息中的任何内容有疑问，或想获取更多背景，请立即调用 `web_search` 工具进行确认和补充。\n5.  **综合撰写报告**: 综合所有信息（原始数据、你脑中生成的图表、以及网络搜索的结果），撰写最终的Markdown报告。报告必须包含：\n    -   **第一部分：定量信息可视化**: 对图表的解读。在Markdown中用 `![图表描述](chart.png)` 的标准语法引用你生成的图表。\n    -   **第二部分：定性信息展示**: 对定性信息的总结、验证和洞察。\n\n## 当前任务的输入数据:\n{input_value}\n\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-wEVqj",
        "measured": {
          "height": 427,
          "width": 320
        },
        "position": {
          "x": 5825.161192626788,
          "y": 2057.8987849386795
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "WebSearchNoAPI-NEkgj",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Performs a basic DuckDuckGo search (HTML scraping). May be subject to rate limits.",
            "display_name": "Web Search",
            "documentation": "",
            "edited": false,
            "field_order": [
              "query",
              "timeout"
            ],
            "frozen": false,
            "icon": "search",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\nfrom urllib.parse import parse_qs, unquote, urlparse\n\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom langflow.custom import Component\nfrom langflow.io import IntInput, MessageTextInput, Output\nfrom langflow.schema import DataFrame\nfrom langflow.services.deps import get_settings_service\n\n\nclass WebSearchComponent(Component):\n    display_name = \"Web Search\"\n    description = \"Performs a basic DuckDuckGo search (HTML scraping). May be subject to rate limits.\"\n    icon = \"search\"\n    name = \"WebSearchNoAPI\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"Keywords to search for.\",\n            tool_mode=True,\n            required=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the web search request.\",\n            value=5,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"results\", display_name=\"Search Results\", method=\"perform_search\")]\n\n    def validate_url(self, string: str) -> bool:\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\" r\"(www\\.)?\" r\"([a-zA-Z0-9.-]+)\" r\"(\\.[a-zA-Z]{2,})?\" r\"(:\\d+)?\" r\"(\\/[^\\s]*)?$\",\n            re.IGNORECASE,\n        )\n        return bool(url_regex.match(string))\n\n    def ensure_url(self, url: str) -> str:\n        if not url.startswith((\"http://\", \"https://\")):\n            url = \"https://\" + url\n        if not self.validate_url(url):\n            msg = f\"Invalid URL: {url}\"\n            raise ValueError(msg)\n        return url\n\n    def _sanitize_query(self, query: str) -> str:\n        \"\"\"Sanitize search query.\"\"\"\n        # Remove potentially dangerous characters\n        return re.sub(r'[<>\"\\']', \"\", query.strip())\n\n    def perform_search(self) -> DataFrame:\n        query = self._sanitize_query(self.query)\n        if not query:\n            msg = \"Empty search query\"\n            raise ValueError(msg)\n        headers = {\"User-Agent\": get_settings_service().settings.user_agent}\n        params = {\"q\": query, \"kl\": \"us-en\"}\n        url = \"https://html.duckduckgo.com/html/\"\n\n        try:\n            response = requests.get(url, params=params, headers=headers, timeout=self.timeout)\n            response.raise_for_status()\n        except requests.RequestException as e:\n            self.status = f\"Failed request: {e!s}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"snippet\": str(e), \"content\": \"\"}]))\n\n        if not response.text or \"text/html\" not in response.headers.get(\"content-type\", \"\").lower():\n            self.status = \"No results found\"\n            return DataFrame(\n                pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"snippet\": \"No results found\", \"content\": \"\"}])\n            )\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        results = []\n\n        for result in soup.select(\"div.result\"):\n            title_tag = result.select_one(\"a.result__a\")\n            snippet_tag = result.select_one(\"a.result__snippet\")\n            if title_tag:\n                raw_link = title_tag.get(\"href\", \"\")\n                parsed = urlparse(raw_link)\n                uddg = parse_qs(parsed.query).get(\"uddg\", [\"\"])[0]\n                decoded_link = unquote(uddg) if uddg else raw_link\n\n                try:\n                    final_url = self.ensure_url(decoded_link)\n                    page = requests.get(final_url, headers=headers, timeout=self.timeout)\n                    page.raise_for_status()\n                    content = BeautifulSoup(page.text, \"lxml\").get_text(separator=\" \", strip=True)\n                except requests.RequestException as e:\n                    final_url = decoded_link\n                    content = f\"(Failed to fetch: {e!s}\"\n\n                results.append(\n                    {\n                        \"title\": title_tag.get_text(strip=True),\n                        \"link\": final_url,\n                        \"snippet\": snippet_tag.get_text(strip=True) if snippet_tag else \"\",\n                        \"content\": content,\n                    }\n                )\n\n        df_results = pd.DataFrame(results)\n        return DataFrame(df_results)\n"
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Keywords to search for.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "Timeout for the web search request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "query": {
                        "description": "Keywords to search for.",
                        "title": "Query",
                        "type": "string"
                      }
                    },
                    "description": "Performs a basic DuckDuckGo search (HTML scraping). May be subject to rate limits.",
                    "display_description": "Performs a basic DuckDuckGo search (HTML scraping). May be subject to rate limits.",
                    "display_name": "perform_search",
                    "name": "perform_search",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "perform_search"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "WebSearchNoAPI"
        },
        "dragging": false,
        "id": "WebSearchNoAPI-NEkgj",
        "measured": {
          "height": 217,
          "width": 320
        },
        "position": {
          "x": 2700.740776099679,
          "y": 3409.870527853643
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PythonPlotterComponent-NEKFU",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
            "display_name": "Python Plotter",
            "documentation": "",
            "edited": true,
            "field_order": [
              "global_imports",
              "python_code"
            ],
            "frozen": false,
            "icon": "chart-line",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import base64\r\nimport importlib\r\nimport io\r\nimport traceback\r\n\r\n# 关键步骤：设置 matplotlib 使用 'Agg' 后端\r\n# 这必须在导入 pyplot 之前完成，以防止它尝试使用 GUI 后端\r\nimport matplotlib\r\nmatplotlib.use(\"Agg\")\r\n\r\nfrom langchain_experimental.utilities import PythonREPL\r\nfrom langflow.custom.custom_component.component import Component\r\nfrom langflow.io import CodeInput, Output, StrInput\r\nfrom langflow.schema.data import Data\r\n\r\n\r\nclass PythonPlotterComponent(Component):\r\n    \"\"\"\r\n    一个可以执行 Python 代码并生成数据可视化图表的组件。\r\n    \"\"\"\r\n    display_name = \"Python Plotter\"\r\n    description = \"执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。\"\r\n    icon = \"chart-line\"\r\n    beta = True\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"global_imports\",\r\n            display_name=\"依赖库导入\",\r\n            info=\"需要导入的 Python 库，用逗号分隔。支持别名，例如 'pandas as pd, matplotlib.pyplot as plt'。\",\r\n            value=\"pandas,matplotlib.pyplot as plt\", # 默认包含 pandas 和 matplotlib\r\n            required=True,\r\n        ),\r\n        CodeInput(\r\n            name=\"python_code\",\r\n            display_name=\"Python 代码\",\r\n            info=\"在此处编写用于数据处理和绘图的 Python 代码。组件会自动捕获生成的图表。\",\r\n            # 提供一个默认的、可直接运行的绘图示例\r\n            value=(\r\n                \"# 1. 创建一个 pandas DataFrame 作为示例数据\\n\"\r\n                \"data = {\\n\"\r\n                \"    '月份': ['一月', '二月', '三月', '四月', '五月'],\\n\"\r\n                \"    '销售额(万)': [23, 45, 55, 48, 62]\\n\"\r\n                \"}\\n\"\r\n                \"df = pandas.DataFrame(data)\\n\\n\"\r\n                \"# 2. 使用 DataFrame 的 plot 功能创建图表\\n\"\r\n                \"# 注意：不需要调用 plt.show()\\n\"\r\n                \"df.plot(x='月份', y='销售额(万)', kind='bar', title='月度销售额分析', legend=False)\\n\"\r\n                \"plt.ylabel('销售额 (万元)')\\n\"\r\n                \"plt.xticks(rotation=0)\\n\"\r\n                \"plt.grid(axis='y', linestyle='--')\\n\"\r\n            ),\r\n            input_types=[\"Message\"],\r\n            tool_mode=True,\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"图表输出\",\r\n            name=\"plot_image\",\r\n            method=\"run_and_plot\",\r\n            type_=Data,\r\n        ),\r\n        Output(\r\n            display_name=\"文本输出\",\r\n            name=\"text_result\",\r\n            method=\"run_and_plot\",\r\n            type_=Data,\r\n        )\r\n    ]\r\n\r\n    def get_globals(self, global_imports: str) -> dict:\r\n        \"\"\"\r\n        根据用户输入的字符串创建一个包含允许导入模块的全局字典。\r\n        增强版：支持 'as' 别名。\r\n        \"\"\"\r\n        global_dict = {}\r\n        modules = [module.strip() for module in global_imports.split(\",\") if module.strip()]\r\n\r\n        for module in modules:\r\n            try:\r\n                if \" as \" in module:\r\n                    module_name, alias = [part.strip() for part in module.split(\" as \")]\r\n                    imported_module = importlib.import_module(module_name)\r\n                    global_dict[alias] = imported_module\r\n                else:\r\n                    imported_module = importlib.import_module(module)\r\n                    global_dict[imported_module.__name__] = imported_module\r\n            except ImportError as e:\r\n                raise ImportError(f\"无法导入模块 '{module.split(' as ')[0]}': {e}\") from e\r\n\r\n        self.log(f\"成功导入模块: {list(global_dict.keys())}\")\r\n        return global_dict\r\n\r\n    def run_and_plot(self) -> list[Data]:\r\n        \"\"\"\r\n        执行用户代码，捕获标准输出和生成的图表。\r\n        \"\"\"\r\n        image_data = Data(data={})\r\n        text_data = Data(data={})\r\n        \r\n        # 必须在这里导入 pyplot，因为它依赖于之前设置的 'Agg' 后端\r\n        import matplotlib.pyplot as plt\r\n\r\n        try:\r\n            # 1. 设置安全的全局变量\r\n            globals_ = self.get_globals(self.global_imports)\r\n            globals_[\"plt\"] = plt # 确保 plt 始终可用\r\n            \r\n            # 2. 执行用户代码\r\n            python_repl = PythonREPL(_globals=globals_)\r\n            text_result = python_repl.run(self.python_code)\r\n            \r\n            # 3. 捕获图表\r\n            # 检查当前是否有活动的图表\r\n            if plt.get_fignums():\r\n                fig = plt.gcf() # Get current figure\r\n\r\n                # 将图表保存到内存缓冲区\r\n                buf = io.BytesIO()\r\n                fig.savefig(buf, format='png', bbox_inches='tight', dpi=150)\r\n                buf.seek(0)\r\n                \r\n                # 将图像编码为 Base64 字符串\r\n                image_base64 = base64.b64encode(buf.read()).decode('utf-8')\r\n                \r\n                # 将 Base64 字符串包装成 Data URI 格式，方便前端显示\r\n                plot_uri = f\"data:image/png;base64,{image_base64}\"\r\n                image_data = Data(data={\"plot\": plot_uri}, artifact_type=\"image\")\r\n                self.log(\"成功生成并捕获图表。\")\r\n\r\n            text_result = text_result.strip() if text_result else \"代码已执行，但没有文本输出。\"\r\n            text_data = Data(data={\"result\": text_result})\r\n            self.log(f\"代码执行的文本输出: {text_result}\")\r\n\r\n        except Exception as e:\r\n            error_message = f\"执行代码时出错: {e}\\n{traceback.format_exc()}\"\r\n            self.log(error_message, level=\"error\")\r\n            # 在两个输出中都报告错误\r\n            error_data = Data(data={\"error\": error_message})\r\n            return [error_data, error_data]\r\n        \r\n        finally:\r\n            # 4. 清理，关闭所有图表以释放内存，防止在多次运行时叠加\r\n            plt.close('all')\r\n\r\n        return [image_data, text_data]"
              },
              "global_imports": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "依赖库导入",
                "dynamic": false,
                "info": "需要导入的 Python 库，用逗号分隔。支持别名，例如 'pandas as pd, matplotlib.pyplot as plt'。",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "global_imports",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "math,pandas,matplotlib,seaborn"
              },
              "python_code": {
                "_input_type": "CodeInput",
                "advanced": false,
                "display_name": "Python 代码",
                "dynamic": false,
                "info": "在此处编写用于数据处理和绘图的 Python 代码。组件会自动捕获生成的图表。",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "python_code",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "type": "code",
                "value": "# 1. 创建一个 pandas DataFrame 作为示例数据\r\n# 在真实场景中，数据可能来自文件或数据库\r\ndata = {\r\n    '月份': ['一月', '二月', '三月', '四月', '五月', '六月'],\r\n    '销售额(万元)': [23, 45, 55, 48, 62, 85]\r\n}\r\ndf = pandas.DataFrame(data)\r\n\r\n# 打印 DataFrame，其输出会显示在“文本输出”中\r\nprint(\"生成的示例数据:\")\r\nprint(df)\r\n\r\n# 2. 使用 DataFrame 的 plot 功能创建图表\r\n#    kind='line' 表示折线图, marker='o' 使数据点更明显\r\ndf.plot(x='月份', y='销售额(万元)', kind='line', marker='o', legend=False)\r\n\r\n# 3. 使用 plt 的函数美化图表\r\n#    注意：不需要调用 plt.show()，组件会自动捕获图像\r\nplt.title('上半年销售额趋势分析')  # 添加图表标题\r\nplt.ylabel('销售额 (万元)')         # 设置 Y 轴标签\r\nplt.xlabel('月份')                 # 设置 X 轴标签\r\nplt.grid(True, linestyle='--', alpha=0.7) # 添加背景网格线，方便阅读\r\nplt.xticks(rotation=0)             # 保持 X 轴标签水平，防止倾斜\r\nplt.tight_layout()                 # 自动调整布局，防止标签重叠"
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "python_code": {
                        "description": "在此处编写用于数据处理和绘图的 Python 代码。组件会自动捕获生成的图表。",
                        "title": "Python Code",
                        "type": "string"
                      }
                    },
                    "description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
                    "display_description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
                    "display_name": "run_and_plot",
                    "name": "run_and_plot",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "run_and_plot"
                    ]
                  },
                  {
                    "args": {
                      "python_code": {
                        "description": "在此处编写用于数据处理和绘图的 Python 代码。组件会自动捕获生成的图表。",
                        "title": "Python Code",
                        "type": "string"
                      }
                    },
                    "description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
                    "display_description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
                    "display_name": "run_and_plot",
                    "name": "run_and_plot",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "run_and_plot"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "PythonPlotterComponent"
        },
        "dragging": false,
        "id": "PythonPlotterComponent-NEKFU",
        "measured": {
          "height": 315,
          "width": 320
        },
        "position": {
          "x": 2696.4086995013563,
          "y": 3696.0221654843667
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OllamaModel-lVS64",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Ollama Local LLMs.",
            "display_name": "Ollama",
            "documentation": "",
            "edited": false,
            "field_order": [
              "base_url",
              "model_name",
              "temperature",
              "format",
              "metadata",
              "mirostat",
              "mirostat_eta",
              "mirostat_tau",
              "num_ctx",
              "num_gpu",
              "num_thread",
              "repeat_last_n",
              "repeat_penalty",
              "tfs_z",
              "timeout",
              "top_k",
              "top_p",
              "verbose",
              "tags",
              "stop_tokens",
              "system",
              "tool_model_enabled",
              "template",
              "input_value",
              "system_message",
              "stream"
            ],
            "frozen": false,
            "icon": "Ollama",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "base_url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Base URL",
                "dynamic": false,
                "info": "Endpoint of the Ollama API.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "base_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:11434"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import asyncio\nfrom typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_ollama import ChatOllama\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.ollama_constants import URL_LIST\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SliderInput\nfrom langflow.logging import logger\n\nHTTP_STATUS_OK = 200\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n    name = \"OllamaModel\"\n\n    # Define constants for JSON keys\n    JSON_MODELS_KEY = \"models\"\n    JSON_NAME_KEY = \"name\"\n    JSON_CAPABILITIES_KEY = \"capabilities\"\n    DESIRED_CAPABILITY = \"completion\"\n    TOOL_CALLING_CAPABILITY = \"tools\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            info=\"Endpoint of the Ollama API.\",\n            value=\"\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=[],\n            info=\"Refer to https://ollama.com/library for more models.\",\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"format\", display_name=\"Format\", info=\"Specify the format of the output (e.g., json).\", advanced=True\n        ),\n        DictInput(name=\"metadata\", display_name=\"Metadata\", info=\"Metadata to add to the run trace.\", advanced=True),\n        DropdownInput(\n            name=\"mirostat\",\n            display_name=\"Mirostat\",\n            options=[\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n            info=\"Enable/disable Mirostat sampling for controlling perplexity.\",\n            value=\"Disabled\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        FloatInput(\n            name=\"mirostat_eta\",\n            display_name=\"Mirostat Eta\",\n            info=\"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"mirostat_tau\",\n            display_name=\"Mirostat Tau\",\n            info=\"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_ctx\",\n            display_name=\"Context Window Size\",\n            info=\"Size of the context window for generating tokens. (Default: 2048)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_gpu\",\n            display_name=\"Number of GPUs\",\n            info=\"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_thread\",\n            display_name=\"Number of Threads\",\n            info=\"Number of threads to use during computation. (Default: detected for optimal performance)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"repeat_last_n\",\n            display_name=\"Repeat Last N\",\n            info=\"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"repeat_penalty\",\n            display_name=\"Repeat Penalty\",\n            info=\"Penalty for repetitions in generated text. (Default: 1.1)\",\n            advanced=True,\n        ),\n        FloatInput(name=\"tfs_z\", display_name=\"TFS Z\", info=\"Tail free sampling value. (Default: 1)\", advanced=True),\n        IntInput(name=\"timeout\", display_name=\"Timeout\", info=\"Timeout for the request stream.\", advanced=True),\n        IntInput(\n            name=\"top_k\", display_name=\"Top K\", info=\"Limits token selection to top K. (Default: 40)\", advanced=True\n        ),\n        FloatInput(name=\"top_p\", display_name=\"Top P\", info=\"Works together with top-k. (Default: 0.9)\", advanced=True),\n        BoolInput(name=\"verbose\", display_name=\"Verbose\", info=\"Whether to print out response text.\", advanced=True),\n        MessageTextInput(\n            name=\"tags\",\n            display_name=\"Tags\",\n            info=\"Comma-separated list of tags to add to the run trace.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"stop_tokens\",\n            display_name=\"Stop Tokens\",\n            info=\"Comma-separated list of tokens to signal the model to stop generating text.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"system\", display_name=\"System\", info=\"System to use for generating text.\", advanced=True\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Tool Model Enabled\",\n            info=\"Whether to enable tool calling in the model.\",\n            value=True,\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"template\", display_name=\"Template\", info=\"Template to use for generating text.\", advanced=True\n        ),\n        *LCModelComponent._base_inputs,\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(self.mirostat, 0)\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n        else:\n            mirostat_eta = self.mirostat_eta\n            mirostat_tau = self.mirostat_tau\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": self.base_url,\n            \"model\": self.model_name,\n            \"mirostat\": mirostat_value,\n            \"format\": self.format,\n            \"metadata\": self.metadata,\n            \"tags\": self.tags.split(\",\") if self.tags else None,\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": self.num_ctx or None,\n            \"num_gpu\": self.num_gpu or None,\n            \"num_thread\": self.num_thread or None,\n            \"repeat_last_n\": self.repeat_last_n or None,\n            \"repeat_penalty\": self.repeat_penalty or None,\n            \"temperature\": self.temperature or None,\n            \"stop\": self.stop_tokens.split(\",\") if self.stop_tokens else None,\n            \"system\": self.system,\n            \"tfs_z\": self.tfs_z or None,\n            \"timeout\": self.timeout or None,\n            \"top_k\": self.top_k or None,\n            \"top_p\": self.top_p or None,\n            \"verbose\": self.verbose,\n            \"template\": self.template,\n        }\n\n        # Remove parameters with None values\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)\n        except Exception as e:\n            msg = (\n                \"Unable to connect to the Ollama API. \",\n                \"Please verify the base URL, ensure the relevant Ollama model is pulled, and try again.\",\n            )\n            raise ValueError(msg) from e\n\n        return output\n\n    async def is_valid_ollama_url(self, url: str) -> bool:\n        try:\n            async with httpx.AsyncClient() as client:\n                return (await client.get(urljoin(url, \"api/tags\"))).status_code == HTTP_STATUS_OK\n        except httpx.RequestError:\n            return False\n\n    async def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"mirostat\":\n            if field_value == \"Disabled\":\n                build_config[\"mirostat_eta\"][\"advanced\"] = True\n                build_config[\"mirostat_tau\"][\"advanced\"] = True\n                build_config[\"mirostat_eta\"][\"value\"] = None\n                build_config[\"mirostat_tau\"][\"value\"] = None\n\n            else:\n                build_config[\"mirostat_eta\"][\"advanced\"] = False\n                build_config[\"mirostat_tau\"][\"advanced\"] = False\n\n                if field_value == \"Mirostat 2.0\":\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.2\n                    build_config[\"mirostat_tau\"][\"value\"] = 10\n                else:\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.1\n                    build_config[\"mirostat_tau\"][\"value\"] = 5\n\n        if field_name in {\"base_url\", \"model_name\"}:\n            if build_config[\"base_url\"].get(\"load_from_db\", False):\n                base_url_value = await self.get_variables(build_config[\"base_url\"].get(\"value\", \"\"), \"base_url\")\n            else:\n                base_url_value = build_config[\"base_url\"].get(\"value\", \"\")\n\n            if not await self.is_valid_ollama_url(base_url_value):\n                # Check if any URL in the list is valid\n                valid_url = \"\"\n                check_urls = URL_LIST\n                if self.base_url:\n                    check_urls = [self.base_url, *URL_LIST]\n                for url in check_urls:\n                    if await self.is_valid_ollama_url(url):\n                        valid_url = url\n                        break\n                if valid_url != \"\":\n                    build_config[\"base_url\"][\"value\"] = valid_url\n                else:\n                    msg = \"No valid Ollama URL found.\"\n                    raise ValueError(msg)\n        if field_name in {\"model_name\", \"base_url\", \"tool_model_enabled\"}:\n            if await self.is_valid_ollama_url(self.base_url):\n                tool_model_enabled = build_config[\"tool_model_enabled\"].get(\"value\", False) or self.tool_model_enabled\n                build_config[\"model_name\"][\"options\"] = await self.get_models(self.base_url, tool_model_enabled)\n            elif await self.is_valid_ollama_url(build_config[\"base_url\"].get(\"value\", \"\")):\n                tool_model_enabled = build_config[\"tool_model_enabled\"].get(\"value\", False) or self.tool_model_enabled\n                build_config[\"model_name\"][\"options\"] = await self.get_models(\n                    build_config[\"base_url\"].get(\"value\", \"\"), tool_model_enabled\n                )\n            else:\n                build_config[\"model_name\"][\"options\"] = []\n        if field_name == \"keep_alive_flag\":\n            if field_value == \"Keep\":\n                build_config[\"keep_alive\"][\"value\"] = \"-1\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            elif field_value == \"Immediately\":\n                build_config[\"keep_alive\"][\"value\"] = \"0\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            else:\n                build_config[\"keep_alive\"][\"advanced\"] = False\n\n        return build_config\n\n    async def get_models(self, base_url_value: str, tool_model_enabled: bool | None = None) -> list[str]:\n        \"\"\"Fetches a list of models from the Ollama API that do not have the \"embedding\" capability.\n\n        Args:\n            base_url_value (str): The base URL of the Ollama API.\n            tool_model_enabled (bool | None, optional): If True, filters the models further to include\n                only those that support tool calling. Defaults to None.\n\n        Returns:\n            list[str]: A list of model names that do not have the \"embedding\" capability. If\n                `tool_model_enabled` is True, only models supporting tool calling are included.\n\n        Raises:\n            ValueError: If there is an issue with the API request or response, or if the model\n                names cannot be retrieved.\n        \"\"\"\n        try:\n            # Normalize the base URL to avoid the repeated \"/\" at the end\n            base_url = base_url_value.rstrip(\"/\") + \"/\"\n\n            # Ollama REST API to return models\n            tags_url = urljoin(base_url, \"api/tags\")\n\n            # Ollama REST API to return model capabilities\n            show_url = urljoin(base_url, \"api/show\")\n\n            async with httpx.AsyncClient() as client:\n                # Fetch available models\n                tags_response = await client.get(tags_url)\n                tags_response.raise_for_status()\n                models = tags_response.json()\n                if asyncio.iscoroutine(models):\n                    models = await models\n                logger.debug(f\"Available models: {models}\")\n\n                # Filter models that are NOT embedding models\n                model_ids = []\n                for model in models[self.JSON_MODELS_KEY]:\n                    model_name = model[self.JSON_NAME_KEY]\n                    logger.debug(f\"Checking model: {model_name}\")\n\n                    payload = {\"model\": model_name}\n                    show_response = await client.post(show_url, json=payload)\n                    show_response.raise_for_status()\n                    json_data = show_response.json()\n                    if asyncio.iscoroutine(json_data):\n                        json_data = await json_data\n                    capabilities = json_data.get(self.JSON_CAPABILITIES_KEY, [])\n                    logger.debug(f\"Model: {model_name}, Capabilities: {capabilities}\")\n\n                    if self.DESIRED_CAPABILITY in capabilities and (\n                        not tool_model_enabled or self.TOOL_CALLING_CAPABILITY in capabilities\n                    ):\n                        model_ids.append(model_name)\n\n        except (httpx.RequestError, ValueError) as e:\n            msg = \"Could not get model names from Ollama.\"\n            raise ValueError(msg) from e\n\n        return model_ids\n"
              },
              "format": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Format",
                "dynamic": false,
                "info": "Specify the format of the output (e.g., json).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "format",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Metadata",
                "dynamic": false,
                "info": "Metadata to add to the run trace.",
                "list": false,
                "list_add_label": "Add More",
                "name": "metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "mirostat": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Mirostat",
                "dynamic": false,
                "info": "Enable/disable Mirostat sampling for controlling perplexity.",
                "name": "mirostat",
                "options": [
                  "Disabled",
                  "Mirostat",
                  "Mirostat 2.0"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Disabled"
              },
              "mirostat_eta": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Mirostat Eta",
                "dynamic": false,
                "info": "Learning rate for Mirostat algorithm. (Default: 0.1)",
                "list": false,
                "list_add_label": "Add More",
                "name": "mirostat_eta",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "mirostat_tau": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Mirostat Tau",
                "dynamic": false,
                "info": "Controls the balance between coherence and diversity of the output. (Default: 5.0)",
                "list": false,
                "list_add_label": "Add More",
                "name": "mirostat_tau",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "Refer to https://ollama.com/library for more models.",
                "name": "model_name",
                "options": [
                  "qwen3:8b"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "qwen3:8b"
              },
              "num_ctx": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Context Window Size",
                "dynamic": false,
                "info": "Size of the context window for generating tokens. (Default: 2048)",
                "list": false,
                "list_add_label": "Add More",
                "name": "num_ctx",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "num_gpu": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of GPUs",
                "dynamic": false,
                "info": "Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)",
                "list": false,
                "list_add_label": "Add More",
                "name": "num_gpu",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "num_thread": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Threads",
                "dynamic": false,
                "info": "Number of threads to use during computation. (Default: detected for optimal performance)",
                "list": false,
                "list_add_label": "Add More",
                "name": "num_thread",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "repeat_last_n": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Repeat Last N",
                "dynamic": false,
                "info": "How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)",
                "list": false,
                "list_add_label": "Add More",
                "name": "repeat_last_n",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "repeat_penalty": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Repeat Penalty",
                "dynamic": false,
                "info": "Penalty for repetitions in generated text. (Default: 1.1)",
                "list": false,
                "list_add_label": "Add More",
                "name": "repeat_penalty",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "stop_tokens": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Stop Tokens",
                "dynamic": false,
                "info": "Comma-separated list of tokens to signal the model to stop generating text.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "stop_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "System",
                "dynamic": false,
                "info": "System to use for generating text.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "system",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "你是一位顶级的开源项目分析师。你的任务是基于给定的定量数据和定性信息，生成一份专业、深入、图文并茂的分析报告。你必须严谨、客观，在不确定时，要主动使用工具进行核实。你的最终产出是一份可以直接发布的Markdown中文报告。"
              },
              "tags": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tags",
                "dynamic": false,
                "info": "Comma-separated list of tags to add to the run trace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tags",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Template",
                "dynamic": false,
                "info": "Template to use for generating text.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "tfs_z": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "TFS Z",
                "dynamic": false,
                "info": "Tail free sampling value. (Default: 1)",
                "list": false,
                "list_add_label": "Add More",
                "name": "tfs_z",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "Timeout for the request stream.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "Whether to enable tool calling in the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Limits token selection to top K. (Default: 40)",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "top_p": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Top P",
                "dynamic": false,
                "info": "Works together with top-k. (Default: 0.9)",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_p",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "Whether to print out response text.",
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "OllamaModel"
        },
        "dragging": false,
        "id": "OllamaModel-lVS64",
        "measured": {
          "height": 573,
          "width": 320
        },
        "position": {
          "x": 2177.763201807911,
          "y": 2688.322265660049
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-WFHAK",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Language Model",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "LanguageModel"
                ],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [
                  {
                    "icon": "Amazon"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "Azure"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Groq"
                  },
                  {
                    "icon": "NVIDIA"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "SambaNova"
                  },
                  {
                    "icon": "brain"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers.current_date import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.custom_component.component import _get_component_toolkit\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.field_typing import Tool\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n            # note the tools are not required to run the agent, hence the validation removed.\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v is not None}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = _get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\", tool_description=description, callbacks=self.get_langchain_callbacks()\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": true,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "input_types": [],
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Retrieve"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "input_types": [],
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "input_types": [],
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# **核心任务与世界观 (Core Mission & Worldview)**\n\n**你的角色**：你是一个自动化的分析报告引擎。\n\n**唯一目标**：严格遵循指令，调用工具，将输入的数据转换为一份包含Base64嵌入式图表的中文Markdown报告。\n\n**世界观 (规则)**：\n\n  - **无文件系统**：你的世界里没有本地文件系统。所有图表操作必须在内存中完成。\n  - **Base64是唯一媒介**：图表数据通过Base64编码在流程中传递。\n  - **自包含输出**：最终报告必须是一个能独立显示的`.md`文件，图表使用`Data URI`方案嵌入。**严禁引用任何外部或本地文件路径**。\n\n-----\n\n# **输入格式 (Input Schema)**\n\n你将收到一个JSON对象。注意，你需要的数据在`\"data\"`键下。\n\n```json\n{\n  \"status\": \"success\",\n  \"data\": [\n    // ... 包含量化数据的对象数组 ...\n  ]\n}\n```\n\n-----\n\n# **你的工具箱 (Your Toolbox)**\n\n你拥有以下工具，必须学会使用它们。\n\n### **工具1: 图表生成器 (`python_plotter`)**\n\n  - **功能**: 执行Python代码，专门用于生成图表并返回其Base64编码。\n  - **调用时机**: **必须**在任务开始时，作为第一步调用此工具。\n  - **核心代码模板 (必须遵循)**:\n    ```python\n    # 核心库，无需重复导入\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    import io\n    import base64\n    import json\n\n    # 假设输入数据已加载到变量 `json_input`\n    # df = pd.DataFrame(json_input['data'])\n\n    # 编写你的数据处理和绘图逻辑\n    # ...\n\n    # --- 关键的输出步骤 ---\n    buf = io.BytesIO()\n    plt.savefig(buf, format='png', bbox_inches='tight', dpi=120)\n    buf.seek(0)\n    image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n    # 将Base64封装在JSON中，通过print函数返回给系统\n    print(json.dumps({\"image_base64\": image_base64}))\n    plt.close() # 清理画布，避免污染\n    ```\n  - **返回值**: `{\"image_base64\": \"iVBORw0KGgoAAA...\"}`\n\n-----\n\n# **绝对执行路径 (The Absolute Execution Path)**\n\n你必须像执行程序一样，严格按照以下思考和行动路径操作。\n\n1.  **(思考)** \"我的首要任务是可视化`quantitative_data`。我需要立即调用`python_plotter`工具，并使用提供的模板编写代码来生成图表。\"\n2.  **(行动)** 调用`python_plotter`工具。\n3.  **(接收)** 从工具的返回结果中，提取并暂存`image_base64`字符串。\n4.  **(思考)** \"图表已生成。由于输入中没有`qualitative_data`，我将直接基于图表和原始数据进行分析，并撰写包含洞察和建议的报告。\"\n5.  **(整合与输出)** 创建最终的、完整的Markdown报告。**报告就是最终答案，禁止在报告后附加任何问题、评论或请求。**\n\n-----\n\n# **完整工作示例 (Complete Working Example)**\n\n**这是你必须学习的范例。**\n\n### **输入:**\n\n```json\n{\n  \"status\": \"success\",\n  \"data\": [\n    { \"uuid\": \"A\", \"score\": 80, \"activity_core_contributor_count\": 5 },\n    { \"uuid\": \"B\", \"score\": 95, \"activity_core_contributor_count\": 10 }\n  ]\n}\n```\n\n### **你的思考与行动:**\n\n**(思考)** 我的首要任务是可视化项目得分和核心贡献者数量。条形图可以很好地展示。我将立刻调用`python_plotter`。\n\n**(行动)**\n**(思考)** 我已成功获取图表的Base64编码。现在，我将整合所有信息，撰写最终报告。\n\n**(最终答案)**\n\n```markdown\n# **项目得分与核心贡献者分析**\n\n### **定量分析与图表**\n\n数据显示，项目得分与其核心贡献者数量存在显著的正相关。项目B的核心贡献者数量（10人）是项目A（5人）的两倍，其得分（95分）也远高于项目A（80分）。下图清晰地展示了这一趋势。\n\n![项目得分与核心贡献者关系](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...（此处为很长的Base64字符串）...CYII=)\n\n### **核心洞察与建议**\n-   **核心贡献者是关键资产**: 核心贡献者的数量是衡量项目健康度和潜力的关键指标，并可能直接影响项目的最终评估分数。\n-   **发展建议**: 为提升项目表现，应优先制定策略吸引和培养核心贡献者，而不仅仅是增加普通参与者数量。\n```\n\n-----\n\n# **== 开始你的任务 ==**\n\n## **当前任务的输入数据:**\n\n`{ \"status\": \"success\", \"data\": [ { \"uuid\": \"1\", \"score\": 85, \"activity_casual_contributor_count\": 10, \"activity_regular_contributor_count\": 5, \"activity_core_contributor_count\": 2 }, { \"uuid\": \"2\", \"score\": 92, \"activity_casual_contributor_count\": 15, \"activity_regular_contributor_count\": 8, \"activity_core_contributor_count\": 4 }, { \"uuid\": \"3\", \"score\": 88, \"activity_casual_contributor_count\": 12, \"activity_regular_contributor_count\": 6, \"activity_core_contributor_count\": 3 } ] }`"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-WFHAK",
        "measured": {
          "height": 427,
          "width": 320
        },
        "position": {
          "x": 3134.2043750064327,
          "y": 2958.9133301521383
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-BVMPU",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([safe_convert(item, clean_data=self.clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "id": "ChatOutput-BVMPU",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 3985.8760656583986,
          "y": 3099.2355009215526
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PythonPlotterComponent-b5rpr",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。",
            "display_name": "Python Plotter",
            "documentation": "",
            "edited": true,
            "field_order": [
              "global_imports",
              "python_code"
            ],
            "frozen": false,
            "icon": "chart-line",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "图表输出",
                "group_outputs": false,
                "hidden": null,
                "method": "run_and_plot",
                "name": "plot_image",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "文本输出",
                "group_outputs": false,
                "hidden": null,
                "method": "run_and_plot",
                "name": "text_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import base64\r\nimport importlib\r\nimport io\r\nimport traceback\r\n\r\n# 关键步骤：设置 matplotlib 使用 'Agg' 后端\r\n# 这必须在导入 pyplot 之前完成，以防止它尝试使用 GUI 后端\r\nimport matplotlib\r\nmatplotlib.use(\"Agg\")\r\n\r\nfrom langchain_experimental.utilities import PythonREPL\r\nfrom langflow.custom.custom_component.component import Component\r\nfrom langflow.io import CodeInput, Output, StrInput\r\nfrom langflow.schema.data import Data\r\n\r\n\r\nclass PythonPlotterComponent(Component):\r\n    \"\"\"\r\n    一个可以执行 Python 代码并生成数据可视化图表的组件。\r\n    \"\"\"\r\n    display_name = \"Python Plotter\"\r\n    description = \"执行 Python 代码来生成图表。请确保代码中包含绘图逻辑 (e.g., using pandas.plot or matplotlib.pyplot)。\"\r\n    icon = \"chart-line\"\r\n    beta = True\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"global_imports\",\r\n            display_name=\"依赖库导入\",\r\n            info=\"需要导入的 Python 库，用逗号分隔。支持别名，例如 'pandas as pd, matplotlib.pyplot as plt'。\",\r\n            value=\"pandas,matplotlib.pyplot as plt\", # 默认包含 pandas 和 matplotlib\r\n            required=True,\r\n        ),\r\n        CodeInput(\r\n            name=\"python_code\",\r\n            display_name=\"Python 代码\",\r\n            info=\"在此处编写用于数据处理和绘图的 Python 代码。组件会自动捕获生成的图表。\",\r\n            # 提供一个默认的、可直接运行的绘图示例\r\n            value=(\r\n                \"# 1. 创建一个 pandas DataFrame 作为示例数据\\n\"\r\n                \"data = {\\n\"\r\n                \"    '月份': ['一月', '二月', '三月', '四月', '五月'],\\n\"\r\n                \"    '销售额(万)': [23, 45, 55, 48, 62]\\n\"\r\n                \"}\\n\"\r\n                \"df = pandas.DataFrame(data)\\n\\n\"\r\n                \"# 2. 使用 DataFrame 的 plot 功能创建图表\\n\"\r\n                \"# 注意：不需要调用 plt.show()\\n\"\r\n                \"df.plot(x='月份', y='销售额(万)', kind='bar', title='月度销售额分析', legend=False)\\n\"\r\n                \"plt.ylabel('销售额 (万元)')\\n\"\r\n                \"plt.xticks(rotation=0)\\n\"\r\n                \"plt.grid(axis='y', linestyle='--')\\n\"\r\n            ),\r\n            input_types=[\"Message\"],\r\n            tool_mode=True,\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"图表输出\",\r\n            name=\"plot_image\",\r\n            method=\"run_and_plot\",\r\n            type_=Data,\r\n        ),\r\n        Output(\r\n            display_name=\"文本输出\",\r\n            name=\"text_result\",\r\n            method=\"run_and_plot\",\r\n            type_=Data,\r\n        )\r\n    ]\r\n\r\n    def get_globals(self, global_imports: str) -> dict:\r\n        \"\"\"\r\n        根据用户输入的字符串创建一个包含允许导入模块的全局字典。\r\n        增强版：支持 'as' 别名。\r\n        \"\"\"\r\n        global_dict = {}\r\n        modules = [module.strip() for module in global_imports.split(\",\") if module.strip()]\r\n\r\n        for module in modules:\r\n            try:\r\n                if \" as \" in module:\r\n                    module_name, alias = [part.strip() for part in module.split(\" as \")]\r\n                    imported_module = importlib.import_module(module_name)\r\n                    global_dict[alias] = imported_module\r\n                else:\r\n                    imported_module = importlib.import_module(module)\r\n                    global_dict[imported_module.__name__] = imported_module\r\n            except ImportError as e:\r\n                raise ImportError(f\"无法导入模块 '{module.split(' as ')[0]}': {e}\") from e\r\n\r\n        self.log(f\"成功导入模块: {list(global_dict.keys())}\")\r\n        return global_dict\r\n\r\n    def run_and_plot(self) -> list[Data]:\r\n        \"\"\"\r\n        执行用户代码，捕获标准输出和生成的图表。\r\n        \"\"\"\r\n        image_data = Data(data={})\r\n        text_data = Data(data={})\r\n        \r\n        # 必须在这里导入 pyplot，因为它依赖于之前设置的 'Agg' 后端\r\n        import matplotlib.pyplot as plt\r\n\r\n        try:\r\n            # 1. 设置安全的全局变量\r\n            globals_ = self.get_globals(self.global_imports)\r\n            globals_[\"plt\"] = plt # 确保 plt 始终可用\r\n            \r\n            # 2. 执行用户代码\r\n            python_repl = PythonREPL(_globals=globals_)\r\n            text_result = python_repl.run(self.python_code)\r\n            \r\n            # 3. 捕获图表\r\n            # 检查当前是否有活动的图表\r\n            if plt.get_fignums():\r\n                fig = plt.gcf() # Get current figure\r\n\r\n                # 将图表保存到内存缓冲区\r\n                buf = io.BytesIO()\r\n                fig.savefig(buf, format='png', bbox_inches='tight', dpi=150)\r\n                buf.seek(0)\r\n                \r\n                # 将图像编码为 Base64 字符串\r\n                image_base64 = base64.b64encode(buf.read()).decode('utf-8')\r\n                \r\n                # 将 Base64 字符串包装成 Data URI 格式，方便前端显示\r\n                plot_uri = f\"data:image/png;base64,{image_base64}\"\r\n                image_data = Data(data={\"plot\": plot_uri}, artifact_type=\"image\")\r\n                self.log(\"成功生成并捕获图表。\")\r\n\r\n            text_result = text_result.strip() if text_result else \"代码已执行，但没有文本输出。\"\r\n            text_data = Data(data={\"result\": text_result})\r\n            self.log(f\"代码执行的文本输出: {text_result}\")\r\n\r\n        except Exception as e:\r\n            error_message = f\"执行代码时出错: {e}\\n{traceback.format_exc()}\"\r\n            self.log(error_message, level=\"error\")\r\n            # 在两个输出中都报告错误\r\n            error_data = Data(data={\"error\": error_message})\r\n            return [error_data, error_data]\r\n        \r\n        finally:\r\n            # 4. 清理，关闭所有图表以释放内存，防止在多次运行时叠加\r\n            plt.close('all')\r\n\r\n        return [image_data, text_data]"
              },
              "global_imports": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "依赖库导入",
                "dynamic": false,
                "info": "需要导入的 Python 库，用逗号分隔。支持别名，例如 'pandas as pd, matplotlib.pyplot as plt'。",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "global_imports",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "math,pandas,matplotlib,seaborn"
              },
              "python_code": {
                "_input_type": "CodeInput",
                "advanced": false,
                "display_name": "Python 代码",
                "dynamic": false,
                "info": "在此处编写用于数据处理和绘图的 Python 代码。组件会自动捕获生成的图表。",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "python_code",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "type": "code",
                "value": "# 1. 创建一个 pandas DataFrame 作为示例数据\r\n# 在真实场景中，数据可能来自文件或数据库\r\ndata = {\r\n    '月份': ['一月', '二月', '三月', '四月', '五月', '六月'],\r\n    '销售额(万元)': [23, 45, 55, 48, 62, 85]\r\n}\r\ndf = pandas.DataFrame(data)\r\n\r\n# 打印 DataFrame，其输出会显示在“文本输出”中\r\nprint(\"生成的示例数据:\")\r\nprint(df)\r\n\r\n# 2. 使用 DataFrame 的 plot 功能创建图表\r\n#    kind='line' 表示折线图, marker='o' 使数据点更明显\r\ndf.plot(x='月份', y='销售额(万元)', kind='line', marker='o', legend=False)\r\n\r\n# 3. 使用 plt 的函数美化图表\r\n#    注意：不需要调用 plt.show()，组件会自动捕获图像\r\nplt.title('上半年销售额趋势分析')  # 添加图表标题\r\nplt.ylabel('销售额 (万元)')         # 设置 Y 轴标签\r\nplt.xlabel('月份')                 # 设置 X 轴标签\r\nplt.grid(True, linestyle='--', alpha=0.7) # 添加背景网格线，方便阅读\r\nplt.xticks(rotation=0)             # 保持 X 轴标签水平，防止倾斜\r\nplt.tight_layout()                 # 自动调整布局，防止标签重叠"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PythonPlotterComponent"
        },
        "dragging": false,
        "id": "PythonPlotterComponent-b5rpr",
        "measured": {
          "height": 323,
          "width": 320
        },
        "position": {
          "x": 3560.2839744497883,
          "y": 3488.0324592168968
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DeepSeekModelComponent-5wPie",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using DeepSeek LLMs.",
            "display_name": "DeepSeek",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "custom_headers",
              "top_p",
              "top_k",
              "frequency_penalty",
              "json_mode",
              "model_name",
              "api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "frozen": false,
            "icon": "DeepSeek",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "API Base",
                "dynamic": false,
                "info": "Base URL for API requests. Defaults to https://api.deepseek.com",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://ai.gitee.com/v1"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "The DeepSeek API Key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "LV41QCCDGLTQLUUUBAM8KXZKCQOS4ZTUTQDGH461"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import requests\r\nfrom pydantic.v1 import SecretStr\r\nfrom typing_extensions import override\r\n\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import (\r\n    BoolInput,\r\n    DictInput,\r\n    DropdownInput,\r\n    IntInput,\r\n    SecretStrInput,\r\n    SliderInput,\r\n    StrInput,\r\n)\r\n\r\nDEEPSEEK_MODELS = [\"deepseek-chat\", \"deepseek-coder\", \"DeepSeek-R1\"]\r\n\r\n\r\nclass DeepSeekModelComponent(LCModelComponent):\r\n    display_name = \"DeepSeek\"\r\n    description = \"Generate text using DeepSeek LLMs.\"\r\n    icon = \"DeepSeek\"\r\n\r\n    inputs = [\r\n        *LCModelComponent._base_inputs,\r\n        IntInput(\r\n            name=\"max_tokens\",\r\n            display_name=\"Max Tokens\",\r\n            advanced=True,\r\n            info=\"Maximum number of tokens to generate. Set to 0 for unlimited.\",\r\n            value=8192,\r\n            range_spec=RangeSpec(min=0, max=128000),\r\n        ),\r\n        DictInput(\r\n            name=\"model_kwargs\",\r\n            display_name=\"Model Kwargs\",\r\n            advanced=True,\r\n            info='Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}',\r\n        ),\r\n        DictInput(\r\n            name=\"custom_headers\",\r\n            display_name=\"Custom Headers\",\r\n            advanced=True,\r\n            info='Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}',\r\n        ),\r\n        SliderInput(\r\n            name=\"top_p\",\r\n            display_name=\"Top P\",\r\n            info=\"Controls diversity via nucleus sampling. This is a standard parameter.\",\r\n            value=0.7,\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        IntInput(\r\n            name=\"top_k\",\r\n            display_name=\"Top K\",\r\n            info=\"Non-standard parameter. The number of highest probability tokens to keep for filtering.\",\r\n            value=50,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"frequency_penalty\",\r\n            display_name=\"Frequency Penalty\",\r\n            info=\"Standard parameter that decreases the model's likelihood to repeat the same line.\",\r\n            value=0.0,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"json_mode\",\r\n            display_name=\"JSON Mode\",\r\n            advanced=True,\r\n            info=\"If True, it will output JSON regardless of passing a schema.\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            info=\"DeepSeek model to use. You can also type a custom model name.\",\r\n            options=DEEPSEEK_MODELS,\r\n            value=\"deepseek-chat\",\r\n            refresh_button=True,\r\n        ),\r\n        StrInput(\r\n            name=\"api_base\",\r\n            display_name=\"API Base\",\r\n            advanced=False,\r\n            info=\"Base URL for API requests. Defaults to https://api.deepseek.com\",\r\n            value=\"https://api.deepseek.com\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"The DeepSeek API Key\",\r\n            advanced=False,\r\n            required=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            info=\"Controls randomness in responses.\",\r\n            value=0.6,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        IntInput(\r\n            name=\"seed\",\r\n            display_name=\"Seed\",\r\n            info=\"The seed controls the reproducibility of the job.\",\r\n            advanced=True,\r\n            value=1,\r\n        ),\r\n    ]\r\n\r\n    def get_models(self) -> list[str]:\r\n        if not self.api_key:\r\n            return DEEPSEEK_MODELS\r\n\r\n        api_base = self.api_base or \"https://api.deepseek.com\"\r\n        url = f\"{api_base.strip('/')}/models\"\r\n        \r\n        try:\r\n            api_key_value = self.api_key.get_secret_value() if isinstance(self.api_key, SecretStr) else self.api_key\r\n            headers = {\"Authorization\": f\"Bearer {api_key_value}\", \"Accept\": \"application/json\"}\r\n            response = requests.get(url, headers=headers, timeout=5)\r\n            response.raise_for_status()\r\n            model_list = response.json()\r\n            fetched_models = [model[\"id\"] for model in model_list.get(\"data\", [])]\r\n            return sorted(list(set(fetched_models + DEEPSEEK_MODELS)))\r\n        except requests.RequestException as e:\r\n            self.status = f\"Error fetching models: {e}\"\r\n            return DEEPSEEK_MODELS\r\n\r\n    @override\r\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\r\n        if field_name in {\"api_key\", \"api_base\", \"model_name\"}:\r\n            models = self.get_models()\r\n            build_config[\"model_name\"][\"options\"] = models\r\n        return build_config\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        try:\r\n            from langchain_openai import ChatOpenAI\r\n        except ImportError as e:\r\n            msg = \"langchain-openai not installed. Please install with `pip install langchain-openai`\"\r\n            raise ImportError(msg) from e\r\n\r\n        api_key_value = None\r\n        if self.api_key:\r\n            if isinstance(self.api_key, SecretStr):\r\n                api_key_value = self.api_key.get_secret_value()\r\n            else:\r\n                api_key_value = self.api_key\r\n        \r\n        # <--- 主要修正逻辑 (MAIN FIX LOGIC) START --->\r\n        model_kwargs = self.model_kwargs or {}\r\n        \r\n        # 1. 处理标准参数 (Handle standard parameters)\r\n        if self.top_p is not None:\r\n            model_kwargs[\"top_p\"] = self.top_p\r\n        if self.frequency_penalty is not None:\r\n            model_kwargs[\"frequency_penalty\"] = self.frequency_penalty\r\n            \r\n        # 2. 处理需要放入 extra_body 的非标准参数 (Handle non-standard parameters for extra_body)\r\n        #    安全地获取或创建 extra_body 字典\r\n        extra_body = model_kwargs.get(\"extra_body\", {})\r\n        if self.top_k is not None:\r\n            extra_body[\"top_k\"] = self.top_k\r\n            \r\n        # 3. 如果 extra_body 中有内容，则将其放回 model_kwargs\r\n        #    (If extra_body is not empty, put it back into model_kwargs)\r\n        if extra_body:\r\n            model_kwargs[\"extra_body\"] = extra_body\r\n        # <--- 主要修正逻辑 (MAIN FIX LOGIC) END --->\r\n\r\n        output = ChatOpenAI(\r\n            model=self.model_name,\r\n            temperature=self.temperature if self.temperature is not None else 0.1,\r\n            max_tokens=self.max_tokens if self.max_tokens else None,\r\n            model_kwargs=model_kwargs, # 使用我们精心构建的 model_kwargs\r\n            base_url=self.api_base,\r\n            api_key=api_key_value,\r\n            streaming=self.stream,\r\n            seed=self.seed,\r\n        )\r\n\r\n        if self.custom_headers:\r\n            output = output.bind(extra_headers=self.custom_headers)\r\n\r\n        if self.json_mode:\r\n            output = output.bind(response_format={\"type\": \"json_object\"})\r\n\r\n        return output\r\n\r\n    def _get_exception_message(self, e: Exception):\r\n        \"\"\"Get message from DeepSeek API exception.\"\"\"\r\n        try:\r\n            from openai import BadRequestError\r\n\r\n            if isinstance(e, BadRequestError):\r\n                message = e.body.get(\"message\")\r\n                if message:\r\n                    return message\r\n        except ImportError:\r\n            pass\r\n        return str(e)"
              },
              "custom_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Custom Headers",
                "dynamic": false,
                "info": "Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "custom_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "X-Failover-Enabled": "true"
                }
              },
              "frequency_penalty": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Frequency Penalty",
                "dynamic": false,
                "info": "Standard parameter that decreases the model's likelihood to repeat the same line.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "frequency_penalty",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "你是谁"
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "Maximum number of tokens to generate. Set to 0 for unlimited.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "DeepSeek model to use. You can also type a custom model name.",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "deepseek-chat",
                  "deepseek-coder",
                  "DeepSeek-R1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "DeepSeek-R1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 1
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Non-standard parameter. The number of highest probability tokens to keep for filtering.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 50
              },
              "top_p": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Top P",
                "dynamic": false,
                "info": "Controls diversity via nucleus sampling. This is a standard parameter.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "top_p",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.11
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DeepSeekModelComponent"
        },
        "dragging": false,
        "id": "DeepSeekModelComponent-5wPie",
        "measured": {
          "height": 707,
          "width": 320
        },
        "position": {
          "x": 792.7729716615116,
          "y": 578.2102128889709
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DeepSeekModelComponent-UAUdL",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using DeepSeek LLMs.",
            "display_name": "DeepSeek",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "custom_headers",
              "top_p",
              "top_k",
              "frequency_penalty",
              "json_mode",
              "model_name",
              "api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "frozen": false,
            "icon": "DeepSeek",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "API Base",
                "dynamic": false,
                "info": "Base URL for API requests. Defaults to https://api.deepseek.com",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://ai.gitee.com/v1"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "The DeepSeek API Key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "LV41QCCDGLTQLUUUBAM8KXZKCQOS4ZTUTQDGH461"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import requests\r\nfrom pydantic.v1 import SecretStr\r\nfrom typing_extensions import override\r\n\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import (\r\n    BoolInput,\r\n    DictInput,\r\n    DropdownInput,\r\n    IntInput,\r\n    SecretStrInput,\r\n    SliderInput,\r\n    StrInput,\r\n)\r\n\r\nDEEPSEEK_MODELS = [\"deepseek-chat\", \"deepseek-coder\", \"DeepSeek-R1\"]\r\n\r\n\r\nclass DeepSeekModelComponent(LCModelComponent):\r\n    display_name = \"DeepSeek\"\r\n    description = \"Generate text using DeepSeek LLMs.\"\r\n    icon = \"DeepSeek\"\r\n\r\n    inputs = [\r\n        *LCModelComponent._base_inputs,\r\n        IntInput(\r\n            name=\"max_tokens\",\r\n            display_name=\"Max Tokens\",\r\n            advanced=True,\r\n            info=\"Maximum number of tokens to generate. Set to 0 for unlimited.\",\r\n            value=8192,\r\n            range_spec=RangeSpec(min=0, max=128000),\r\n        ),\r\n        DictInput(\r\n            name=\"model_kwargs\",\r\n            display_name=\"Model Kwargs\",\r\n            advanced=True,\r\n            info='Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}',\r\n        ),\r\n        DictInput(\r\n            name=\"custom_headers\",\r\n            display_name=\"Custom Headers\",\r\n            advanced=True,\r\n            info='Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}',\r\n        ),\r\n        SliderInput(\r\n            name=\"top_p\",\r\n            display_name=\"Top P\",\r\n            info=\"Controls diversity via nucleus sampling. This is a standard parameter.\",\r\n            value=0.7,\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        IntInput(\r\n            name=\"top_k\",\r\n            display_name=\"Top K\",\r\n            info=\"Non-standard parameter. The number of highest probability tokens to keep for filtering.\",\r\n            value=50,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"frequency_penalty\",\r\n            display_name=\"Frequency Penalty\",\r\n            info=\"Standard parameter that decreases the model's likelihood to repeat the same line.\",\r\n            value=0.0,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"json_mode\",\r\n            display_name=\"JSON Mode\",\r\n            advanced=True,\r\n            info=\"If True, it will output JSON regardless of passing a schema.\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            info=\"DeepSeek model to use. You can also type a custom model name.\",\r\n            options=DEEPSEEK_MODELS,\r\n            value=\"deepseek-chat\",\r\n            refresh_button=True,\r\n        ),\r\n        StrInput(\r\n            name=\"api_base\",\r\n            display_name=\"API Base\",\r\n            advanced=False,\r\n            info=\"Base URL for API requests. Defaults to https://api.deepseek.com\",\r\n            value=\"https://api.deepseek.com\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"The DeepSeek API Key\",\r\n            advanced=False,\r\n            required=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            info=\"Controls randomness in responses.\",\r\n            value=0.6,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        IntInput(\r\n            name=\"seed\",\r\n            display_name=\"Seed\",\r\n            info=\"The seed controls the reproducibility of the job.\",\r\n            advanced=True,\r\n            value=1,\r\n        ),\r\n    ]\r\n\r\n    def get_models(self) -> list[str]:\r\n        if not self.api_key:\r\n            return DEEPSEEK_MODELS\r\n\r\n        api_base = self.api_base or \"https://api.deepseek.com\"\r\n        url = f\"{api_base.strip('/')}/models\"\r\n        \r\n        try:\r\n            api_key_value = self.api_key.get_secret_value() if isinstance(self.api_key, SecretStr) else self.api_key\r\n            headers = {\"Authorization\": f\"Bearer {api_key_value}\", \"Accept\": \"application/json\"}\r\n            response = requests.get(url, headers=headers, timeout=5)\r\n            response.raise_for_status()\r\n            model_list = response.json()\r\n            fetched_models = [model[\"id\"] for model in model_list.get(\"data\", [])]\r\n            return sorted(list(set(fetched_models + DEEPSEEK_MODELS)))\r\n        except requests.RequestException as e:\r\n            self.status = f\"Error fetching models: {e}\"\r\n            return DEEPSEEK_MODELS\r\n\r\n    @override\r\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\r\n        if field_name in {\"api_key\", \"api_base\", \"model_name\"}:\r\n            models = self.get_models()\r\n            build_config[\"model_name\"][\"options\"] = models\r\n        return build_config\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        try:\r\n            from langchain_openai import ChatOpenAI\r\n        except ImportError as e:\r\n            msg = \"langchain-openai not installed. Please install with `pip install langchain-openai`\"\r\n            raise ImportError(msg) from e\r\n\r\n        api_key_value = None\r\n        if self.api_key:\r\n            if isinstance(self.api_key, SecretStr):\r\n                api_key_value = self.api_key.get_secret_value()\r\n            else:\r\n                api_key_value = self.api_key\r\n        \r\n        # <--- 主要修正逻辑 (MAIN FIX LOGIC) START --->\r\n        model_kwargs = self.model_kwargs or {}\r\n        \r\n        # 1. 处理标准参数 (Handle standard parameters)\r\n        if self.top_p is not None:\r\n            model_kwargs[\"top_p\"] = self.top_p\r\n        if self.frequency_penalty is not None:\r\n            model_kwargs[\"frequency_penalty\"] = self.frequency_penalty\r\n            \r\n        # 2. 处理需要放入 extra_body 的非标准参数 (Handle non-standard parameters for extra_body)\r\n        #    安全地获取或创建 extra_body 字典\r\n        extra_body = model_kwargs.get(\"extra_body\", {})\r\n        if self.top_k is not None:\r\n            extra_body[\"top_k\"] = self.top_k\r\n            \r\n        # 3. 如果 extra_body 中有内容，则将其放回 model_kwargs\r\n        #    (If extra_body is not empty, put it back into model_kwargs)\r\n        if extra_body:\r\n            model_kwargs[\"extra_body\"] = extra_body\r\n        # <--- 主要修正逻辑 (MAIN FIX LOGIC) END --->\r\n\r\n        output = ChatOpenAI(\r\n            model=self.model_name,\r\n            temperature=self.temperature if self.temperature is not None else 0.1,\r\n            max_tokens=self.max_tokens if self.max_tokens else None,\r\n            model_kwargs=model_kwargs, # 使用我们精心构建的 model_kwargs\r\n            base_url=self.api_base,\r\n            api_key=api_key_value,\r\n            streaming=self.stream,\r\n            seed=self.seed,\r\n        )\r\n\r\n        if self.custom_headers:\r\n            output = output.bind(extra_headers=self.custom_headers)\r\n\r\n        if self.json_mode:\r\n            output = output.bind(response_format={\"type\": \"json_object\"})\r\n\r\n        return output\r\n\r\n    def _get_exception_message(self, e: Exception):\r\n        \"\"\"Get message from DeepSeek API exception.\"\"\"\r\n        try:\r\n            from openai import BadRequestError\r\n\r\n            if isinstance(e, BadRequestError):\r\n                message = e.body.get(\"message\")\r\n                if message:\r\n                    return message\r\n        except ImportError:\r\n            pass\r\n        return str(e)"
              },
              "custom_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Custom Headers",
                "dynamic": false,
                "info": "Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "custom_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "X-Failover-Enabled": "true"
                }
              },
              "frequency_penalty": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Frequency Penalty",
                "dynamic": false,
                "info": "Standard parameter that decreases the model's likelihood to repeat the same line.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "frequency_penalty",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "Maximum number of tokens to generate. Set to 0 for unlimited.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "DeepSeek model to use. You can also type a custom model name.",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "deepseek-chat",
                  "deepseek-coder",
                  "DeepSeek-R1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "DeepSeek-R1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# 角色: 高级指令解析器\n\n## 你的任务:\n你的唯一任务是解析用户的自然语言请求，并提取出两个关键信息：用户想要分析的“开源社区名称”和他们的“分析目标”。\n\n## 规则:\n1.  **社区名称 (community_name)**: 必须是标准化的、适合用于API查询的名称（例如，小写，用连字符连接）。\n2.  **分析目标 (analysis_goal)**: 总结用户的核心意图。如果用户没有明确说明，就默认为“全面的社区健康度分析”。\n3.  **严格按照下面的JSON格式输出**，绝不能添加任何额外的解释或文字。\n\n## 示例:\n-   **用户输入**: \"请为我分析openEuler社区的生态健康度\"\n-   **你的输出**:\n    ```json\n    {\n      \"community_name\": \"openeuler\",\n      \"analysis_goal\": \"分析社区生态健康度\"\n    }\n    ```\n-   **用户输入**: \"我想看看 Apache Spark 项目的贡献者情况\"\n-   **你的输出**:\n    ```json\n    {\n      \"community_name\": \"apache-spark\",\n      \"analysis_goal\": \"调查贡献者情况\"\n    }\n    ```\n-   **用户输入**: \"Kubernetes最近怎么样？\"\n-   **你的输出**:\n    ```json\n    {\n      \"community_name\": \"kubernetes\",\n      \"analysis_goal\": \"全面的社区健康度分析\"\n    }\n    ```"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 1
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Non-standard parameter. The number of highest probability tokens to keep for filtering.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 50
              },
              "top_p": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Top P",
                "dynamic": false,
                "info": "Controls diversity via nucleus sampling. This is a standard parameter.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "top_p",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.11
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DeepSeekModelComponent"
        },
        "dragging": false,
        "id": "DeepSeekModelComponent-UAUdL",
        "measured": {
          "height": 707,
          "width": 320
        },
        "position": {
          "x": 1943.2817820865919,
          "y": 996.4910634673379
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DeepSeekModelComponent-xlJ45",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using DeepSeek LLMs.",
            "display_name": "DeepSeek",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "custom_headers",
              "top_p",
              "top_k",
              "frequency_penalty",
              "json_mode",
              "model_name",
              "api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "frozen": false,
            "icon": "DeepSeek",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "API Base",
                "dynamic": false,
                "info": "Base URL for API requests. Defaults to https://api.deepseek.com",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://ai.gitee.com/v1"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "The DeepSeek API Key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "LV41QCCDGLTQLUUUBAM8KXZKCQOS4ZTUTQDGH461"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import requests\r\nfrom pydantic.v1 import SecretStr\r\nfrom typing_extensions import override\r\n\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import (\r\n    BoolInput,\r\n    DictInput,\r\n    DropdownInput,\r\n    IntInput,\r\n    SecretStrInput,\r\n    SliderInput,\r\n    StrInput,\r\n)\r\n\r\nDEEPSEEK_MODELS = [\"deepseek-chat\", \"deepseek-coder\", \"DeepSeek-R1\"]\r\n\r\n\r\nclass DeepSeekModelComponent(LCModelComponent):\r\n    display_name = \"DeepSeek\"\r\n    description = \"Generate text using DeepSeek LLMs.\"\r\n    icon = \"DeepSeek\"\r\n\r\n    inputs = [\r\n        *LCModelComponent._base_inputs,\r\n        IntInput(\r\n            name=\"max_tokens\",\r\n            display_name=\"Max Tokens\",\r\n            advanced=True,\r\n            info=\"Maximum number of tokens to generate. Set to 0 for unlimited.\",\r\n            value=8192,\r\n            range_spec=RangeSpec(min=0, max=128000),\r\n        ),\r\n        DictInput(\r\n            name=\"model_kwargs\",\r\n            display_name=\"Model Kwargs\",\r\n            advanced=True,\r\n            info='Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}',\r\n        ),\r\n        DictInput(\r\n            name=\"custom_headers\",\r\n            display_name=\"Custom Headers\",\r\n            advanced=True,\r\n            info='Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}',\r\n        ),\r\n        SliderInput(\r\n            name=\"top_p\",\r\n            display_name=\"Top P\",\r\n            info=\"Controls diversity via nucleus sampling. This is a standard parameter.\",\r\n            value=0.7,\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        IntInput(\r\n            name=\"top_k\",\r\n            display_name=\"Top K\",\r\n            info=\"Non-standard parameter. The number of highest probability tokens to keep for filtering.\",\r\n            value=50,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"frequency_penalty\",\r\n            display_name=\"Frequency Penalty\",\r\n            info=\"Standard parameter that decreases the model's likelihood to repeat the same line.\",\r\n            value=0.0,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"json_mode\",\r\n            display_name=\"JSON Mode\",\r\n            advanced=True,\r\n            info=\"If True, it will output JSON regardless of passing a schema.\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            info=\"DeepSeek model to use. You can also type a custom model name.\",\r\n            options=DEEPSEEK_MODELS,\r\n            value=\"deepseek-chat\",\r\n            refresh_button=True,\r\n        ),\r\n        StrInput(\r\n            name=\"api_base\",\r\n            display_name=\"API Base\",\r\n            advanced=False,\r\n            info=\"Base URL for API requests. Defaults to https://api.deepseek.com\",\r\n            value=\"https://api.deepseek.com\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"The DeepSeek API Key\",\r\n            advanced=False,\r\n            required=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            info=\"Controls randomness in responses.\",\r\n            value=0.6,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        IntInput(\r\n            name=\"seed\",\r\n            display_name=\"Seed\",\r\n            info=\"The seed controls the reproducibility of the job.\",\r\n            advanced=True,\r\n            value=1,\r\n        ),\r\n    ]\r\n\r\n    def get_models(self) -> list[str]:\r\n        if not self.api_key:\r\n            return DEEPSEEK_MODELS\r\n\r\n        api_base = self.api_base or \"https://api.deepseek.com\"\r\n        url = f\"{api_base.strip('/')}/models\"\r\n        \r\n        try:\r\n            api_key_value = self.api_key.get_secret_value() if isinstance(self.api_key, SecretStr) else self.api_key\r\n            headers = {\"Authorization\": f\"Bearer {api_key_value}\", \"Accept\": \"application/json\"}\r\n            response = requests.get(url, headers=headers, timeout=5)\r\n            response.raise_for_status()\r\n            model_list = response.json()\r\n            fetched_models = [model[\"id\"] for model in model_list.get(\"data\", [])]\r\n            return sorted(list(set(fetched_models + DEEPSEEK_MODELS)))\r\n        except requests.RequestException as e:\r\n            self.status = f\"Error fetching models: {e}\"\r\n            return DEEPSEEK_MODELS\r\n\r\n    @override\r\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\r\n        if field_name in {\"api_key\", \"api_base\", \"model_name\"}:\r\n            models = self.get_models()\r\n            build_config[\"model_name\"][\"options\"] = models\r\n        return build_config\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        try:\r\n            from langchain_openai import ChatOpenAI\r\n        except ImportError as e:\r\n            msg = \"langchain-openai not installed. Please install with `pip install langchain-openai`\"\r\n            raise ImportError(msg) from e\r\n\r\n        api_key_value = None\r\n        if self.api_key:\r\n            if isinstance(self.api_key, SecretStr):\r\n                api_key_value = self.api_key.get_secret_value()\r\n            else:\r\n                api_key_value = self.api_key\r\n        \r\n        # <--- 主要修正逻辑 (MAIN FIX LOGIC) START --->\r\n        model_kwargs = self.model_kwargs or {}\r\n        \r\n        # 1. 处理标准参数 (Handle standard parameters)\r\n        if self.top_p is not None:\r\n            model_kwargs[\"top_p\"] = self.top_p\r\n        if self.frequency_penalty is not None:\r\n            model_kwargs[\"frequency_penalty\"] = self.frequency_penalty\r\n            \r\n        # 2. 处理需要放入 extra_body 的非标准参数 (Handle non-standard parameters for extra_body)\r\n        #    安全地获取或创建 extra_body 字典\r\n        extra_body = model_kwargs.get(\"extra_body\", {})\r\n        if self.top_k is not None:\r\n            extra_body[\"top_k\"] = self.top_k\r\n            \r\n        # 3. 如果 extra_body 中有内容，则将其放回 model_kwargs\r\n        #    (If extra_body is not empty, put it back into model_kwargs)\r\n        if extra_body:\r\n            model_kwargs[\"extra_body\"] = extra_body\r\n        # <--- 主要修正逻辑 (MAIN FIX LOGIC) END --->\r\n\r\n        output = ChatOpenAI(\r\n            model=self.model_name,\r\n            temperature=self.temperature if self.temperature is not None else 0.1,\r\n            max_tokens=self.max_tokens if self.max_tokens else None,\r\n            model_kwargs=model_kwargs, # 使用我们精心构建的 model_kwargs\r\n            base_url=self.api_base,\r\n            api_key=api_key_value,\r\n            streaming=self.stream,\r\n            seed=self.seed,\r\n        )\r\n\r\n        if self.custom_headers:\r\n            output = output.bind(extra_headers=self.custom_headers)\r\n\r\n        if self.json_mode:\r\n            output = output.bind(response_format={\"type\": \"json_object\"})\r\n\r\n        return output\r\n\r\n    def _get_exception_message(self, e: Exception):\r\n        \"\"\"Get message from DeepSeek API exception.\"\"\"\r\n        try:\r\n            from openai import BadRequestError\r\n\r\n            if isinstance(e, BadRequestError):\r\n                message = e.body.get(\"message\")\r\n                if message:\r\n                    return message\r\n        except ImportError:\r\n            pass\r\n        return str(e)"
              },
              "custom_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Custom Headers",
                "dynamic": false,
                "info": "Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "custom_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "X-Failover-Enabled": "true"
                }
              },
              "frequency_penalty": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Frequency Penalty",
                "dynamic": false,
                "info": "Standard parameter that decreases the model's likelihood to repeat the same line.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "frequency_penalty",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "Maximum number of tokens to generate. Set to 0 for unlimited.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "DeepSeek model to use. You can also type a custom model name.",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "deepseek-chat",
                  "deepseek-coder",
                  "DeepSeek-R1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "DeepSeek-R1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# 角色: 分析任务规划师\n\n## 你的任务:\n接收包含“community_name”（仓库URL）和“analysis_goal”的JSON，并创建两个固定任务：一个用于获取定量贡献者数据，另一个用于搜索定性信息。\n\n## 输入的指令:\n{\n  \"community_name\": \"https://github.com/oss-compass/compass-web-service\",\n  \"analysis_goal\": \"分析贡献者画像和社区影响力\"\n}\n\n## 你的输出 (必须是包含任务清单的JSON):\n```json\n{\n  \"repo_url\": \"[https://github.com/oss-compass/compass-web-service](https://github.com/oss-compass/compass-web-service)\",\n  \"task_list\": [\n    {\n      \"task_description\": \"获取该仓库的贡献者里程碑画像数据\",\n      \"task_type\": \"api\"\n    },\n    {\n      \"task_description\": \"搜索关于该仓库或其所属社区的近期新闻和影响力\",\n      \"task_type\": \"search\",\n      \"query\": \"[https://github.com/oss-compass/compass-web-service](https://github.com/oss-compass/compass-web-service) community news and influence\"\n    }\n  ]\n}"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 1
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Non-standard parameter. The number of highest probability tokens to keep for filtering.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 50
              },
              "top_p": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Top P",
                "dynamic": false,
                "info": "Controls diversity via nucleus sampling. This is a standard parameter.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "top_p",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.11
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DeepSeekModelComponent"
        },
        "dragging": false,
        "id": "DeepSeekModelComponent-xlJ45",
        "measured": {
          "height": 707,
          "width": 320
        },
        "position": {
          "x": 2770.755489458882,
          "y": 1036.251755484436
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DeepSeekModelComponent-oAhnt",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using DeepSeek LLMs.",
            "display_name": "DeepSeek",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "api_base",
              "api_key",
              "model_name",
              "tool_model_enabled",
              "temperature",
              "top_p",
              "max_tokens",
              "model_kwargs",
              "custom_headers",
              "top_k",
              "frequency_penalty",
              "json_mode",
              "seed"
            ],
            "frozen": false,
            "icon": "DeepSeek",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "API Base",
                "dynamic": false,
                "info": "Base URL for API requests. Defaults to https://api.deepseek.com",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://ai.gitee.com/v1"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "The DeepSeek API Key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "LV41QCCDGLTQLUUUBAM8KXZKCQOS4ZTUTQDGH461"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import requests\r\nfrom pydantic.v1 import SecretStr\r\nfrom typing_extensions import override\r\n\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import (\r\n    BoolInput,\r\n    DictInput,\r\n    DropdownInput,\r\n    IntInput,\r\n    SecretStrInput,\r\n    SliderInput,\r\n    StrInput,\r\n)\r\n\r\nDEEPSEEK_MODELS = [\"deepseek-chat\", \"deepseek-coder\", \"DeepSeek-R1\"]\r\n\r\n\r\nclass DeepSeekModelComponent(LCModelComponent):\r\n    display_name = \"DeepSeek\"\r\n    description = \"Generate text using DeepSeek LLMs.\"\r\n    icon = \"DeepSeek\"\r\n\r\n    inputs = [\r\n        *LCModelComponent._base_inputs,\r\n        StrInput(\r\n            name=\"api_base\",\r\n            display_name=\"API Base\",\r\n            advanced=False,\r\n            info=\"Base URL for API requests. Defaults to https://api.deepseek.com\",\r\n            value=\"https://api.deepseek.com\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"The DeepSeek API Key\",\r\n            advanced=False,\r\n            required=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            info=\"DeepSeek model to use. You can also type a custom model name.\",\r\n            options=DEEPSEEK_MODELS,\r\n            value=\"deepseek-chat\",\r\n            refresh_button=True,\r\n        ),\r\n        # <--- 修正部分：改回布尔开关 (CORRECTED PART: Changed back to a boolean switch) --->\r\n        BoolInput(\r\n            name=\"tool_model_enabled\",\r\n            display_name=\"Tool Model Enabled\",\r\n            info=\"When enabled, sets tool_choice to 'auto', allowing the model to use connected tools.\",\r\n            value=False, # 默认为关闭\r\n            advanced=False,\r\n        ),\r\n        # <--- 修正部分结束 --->\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            info=\"Controls randomness in responses.\",\r\n            value=0.6,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        SliderInput(\r\n            name=\"top_p\",\r\n            display_name=\"Top P\",\r\n            info=\"Controls diversity via nucleus sampling. This is a standard parameter.\",\r\n            value=0.7,\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        IntInput(\r\n            name=\"max_tokens\",\r\n            display_name=\"Max Tokens\",\r\n            advanced=True,\r\n            info=\"Maximum number of tokens to generate. Set to 0 for unlimited.\",\r\n            value=8192,\r\n            range_spec=RangeSpec(min=0, max=128000),\r\n        ),\r\n        DictInput(\r\n            name=\"model_kwargs\",\r\n            display_name=\"Model Kwargs\",\r\n            advanced=True,\r\n            info='Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}',\r\n        ),\r\n        DictInput(\r\n            name=\"custom_headers\",\r\n            display_name=\"Custom Headers\",\r\n            advanced=True,\r\n            info='Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}',\r\n        ),\r\n        IntInput(\r\n            name=\"top_k\",\r\n            display_name=\"Top K\",\r\n            info=\"Non-standard parameter. The number of highest probability tokens to keep for filtering.\",\r\n            value=50,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"frequency_penalty\",\r\n            display_name=\"Frequency Penalty\",\r\n            info=\"Standard parameter that decreases the model's likelihood to repeat the same line.\",\r\n            value=0.0,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"json_mode\",\r\n            display_name=\"JSON Mode\",\r\n            advanced=True,\r\n            info=\"If True, it will output JSON regardless of passing a schema.\",\r\n        ),\r\n        IntInput(\r\n            name=\"seed\",\r\n            display_name=\"Seed\",\r\n            info=\"The seed controls the reproducibility of the job.\",\r\n            advanced=True,\r\n            value=1,\r\n        ),\r\n    ]\r\n\r\n    def get_models(self) -> list[str]:\r\n        if not self.api_key:\r\n            return DEEPSEEK_MODELS\r\n\r\n        api_base = self.api_base or \"https://api.deepseek.com\"\r\n        url = f\"{api_base.strip('/')}/models\"\r\n        \r\n        try:\r\n            api_key_value = self.api_key.get_secret_value() if isinstance(self.api_key, SecretStr) else self.api_key\r\n            headers = {\"Authorization\": f\"Bearer {api_key_value}\", \"Accept\": \"application/json\"}\r\n            response = requests.get(url, headers=headers, timeout=5)\r\n            response.raise_for_status()\r\n            model_list = response.json()\r\n            fetched_models = [model[\"id\"] for model in model_list.get(\"data\", [])]\r\n            return sorted(list(set(fetched_models + DEEPSEEK_MODELS)))\r\n        except requests.RequestException as e:\r\n            self.status = f\"Error fetching models: {e}\"\r\n            return DEEPSEEK_MODELS\r\n\r\n    @override\r\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\r\n        if field_name in {\"api_key\", \"api_base\", \"model_name\"}:\r\n            models = self.get_models()\r\n            build_config[\"model_name\"][\"options\"] = models\r\n        return build_config\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        try:\r\n            from langchain_openai import ChatOpenAI\r\n        except ImportError as e:\r\n            msg = \"langchain-openai not installed. Please install with `pip install langchain-openai`\"\r\n            raise ImportError(msg) from e\r\n\r\n        api_key_value = None\r\n        if self.api_key:\r\n            if isinstance(self.api_key, SecretStr):\r\n                api_key_value = self.api_key.get_secret_value()\r\n            else:\r\n                api_key_value = self.api_key\r\n        \r\n        model_kwargs = self.model_kwargs or {}\r\n        \r\n        if self.top_p is not None:\r\n            model_kwargs[\"top_p\"] = self.top_p\r\n        if self.frequency_penalty is not None:\r\n            model_kwargs[\"frequency_penalty\"] = self.frequency_penalty\r\n            \r\n        extra_body = model_kwargs.get(\"extra_body\", {})\r\n        if self.top_k is not None:\r\n            extra_body[\"top_k\"] = self.top_k\r\n            \r\n        if extra_body:\r\n            model_kwargs[\"extra_body\"] = extra_body\r\n\r\n        # <--- 修正部分：根据开关状态设置 tool_choice (CORRECTED PART: set tool_choice based on the switch state) --->\r\n        if self.tool_model_enabled:\r\n            model_kwargs[\"tool_choice\"] = \"auto\"\r\n        # <--- 修正部分结束 --->\r\n            \r\n        output = ChatOpenAI(\r\n            model=self.model_name,\r\n            temperature=self.temperature if self.temperature is not None else 0.1,\r\n            max_tokens=self.max_tokens if self.max_tokens else None,\r\n            model_kwargs=model_kwargs,\r\n            base_url=self.api_base,\r\n            api_key=api_key_value,\r\n            streaming=self.stream,\r\n            seed=self.seed,\r\n        )\r\n\r\n        if self.custom_headers:\r\n            output = output.bind(extra_headers=self.custom_headers)\r\n\r\n        if self.json_mode:\r\n            output = output.bind(response_format={\"type\": \"json_object\"})\r\n\r\n        return output\r\n\r\n    def _get_exception_message(self, e: Exception):\r\n        \"\"\"Get message from DeepSeek API exception.\"\"\"\r\n        try:\r\n            from openai import BadRequestError\r\n\r\n            if isinstance(e, BadRequestError):\r\n                message = e.body.get(\"message\")\r\n                if message:\r\n                    return message\r\n        except ImportError:\r\n            pass\r\n        return str(e)"
              },
              "custom_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Custom Headers",
                "dynamic": false,
                "info": "Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "custom_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "X-Failover-Enabled": "true"
                }
              },
              "frequency_penalty": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Frequency Penalty",
                "dynamic": false,
                "info": "Standard parameter that decreases the model's likelihood to repeat the same line.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "frequency_penalty",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "Maximum number of tokens to generate. Set to 0 for unlimited.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "DeepSeek model to use. You can also type a custom model name.",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "deepseek-chat",
                  "deepseek-coder",
                  "DeepSeek-R1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "你是一个专家级的数据获取代理。你的唯一目标是理解一个计划，并使用可用的工具从像OSS-Compass API这样的外部来源获取原始数据。你必须做到精确和高效。"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "When enabled, sets tool_choice to 'auto', allowing the model to use connected tools.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Non-standard parameter. The number of highest probability tokens to keep for filtering.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 50
              },
              "top_p": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Top P",
                "dynamic": false,
                "info": "Controls diversity via nucleus sampling. This is a standard parameter.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "top_p",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.11
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "DeepSeekModelComponent"
        },
        "dragging": false,
        "id": "DeepSeekModelComponent-oAhnt",
        "measured": {
          "height": 749,
          "width": 320
        },
        "position": {
          "x": 3704.4536084757688,
          "y": 797.1928935019331
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DeepSeekModelComponent-dM0pr",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using DeepSeek LLMs.",
            "display_name": "DeepSeek",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "api_base",
              "api_key",
              "model_name",
              "tool_model_enabled",
              "temperature",
              "top_p",
              "max_tokens",
              "model_kwargs",
              "custom_headers",
              "top_k",
              "frequency_penalty",
              "json_mode",
              "seed"
            ],
            "frozen": false,
            "icon": "DeepSeek",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "API Base",
                "dynamic": false,
                "info": "Base URL for API requests. Defaults to https://api.deepseek.com",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://ai.gitee.com/v1"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "The DeepSeek API Key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "LV41QCCDGLTQLUUUBAM8KXZKCQOS4ZTUTQDGH461"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import requests\r\nfrom pydantic.v1 import SecretStr\r\nfrom typing_extensions import override\r\n\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import (\r\n    BoolInput,\r\n    DictInput,\r\n    DropdownInput,\r\n    IntInput,\r\n    SecretStrInput,\r\n    SliderInput,\r\n    StrInput,\r\n)\r\n\r\nDEEPSEEK_MODELS = [\"deepseek-chat\", \"deepseek-coder\", \"DeepSeek-R1\"]\r\n\r\n\r\nclass DeepSeekModelComponent(LCModelComponent):\r\n    display_name = \"DeepSeek\"\r\n    description = \"Generate text using DeepSeek LLMs.\"\r\n    icon = \"DeepSeek\"\r\n\r\n    inputs = [\r\n        *LCModelComponent._base_inputs,\r\n        StrInput(\r\n            name=\"api_base\",\r\n            display_name=\"API Base\",\r\n            advanced=False,\r\n            info=\"Base URL for API requests. Defaults to https://api.deepseek.com\",\r\n            value=\"https://api.deepseek.com\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"The DeepSeek API Key\",\r\n            advanced=False,\r\n            required=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            info=\"DeepSeek model to use. You can also type a custom model name.\",\r\n            options=DEEPSEEK_MODELS,\r\n            value=\"deepseek-chat\",\r\n            refresh_button=True,\r\n        ),\r\n        # <--- 修正部分：改回布尔开关 (CORRECTED PART: Changed back to a boolean switch) --->\r\n        BoolInput(\r\n            name=\"tool_model_enabled\",\r\n            display_name=\"Tool Model Enabled\",\r\n            info=\"When enabled, sets tool_choice to 'auto', allowing the model to use connected tools.\",\r\n            value=False, # 默认为关闭\r\n            advanced=False,\r\n        ),\r\n        # <--- 修正部分结束 --->\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            info=\"Controls randomness in responses.\",\r\n            value=0.6,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        SliderInput(\r\n            name=\"top_p\",\r\n            display_name=\"Top P\",\r\n            info=\"Controls diversity via nucleus sampling. This is a standard parameter.\",\r\n            value=0.7,\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        IntInput(\r\n            name=\"max_tokens\",\r\n            display_name=\"Max Tokens\",\r\n            advanced=True,\r\n            info=\"Maximum number of tokens to generate. Set to 0 for unlimited.\",\r\n            value=8192,\r\n            range_spec=RangeSpec(min=0, max=128000),\r\n        ),\r\n        DictInput(\r\n            name=\"model_kwargs\",\r\n            display_name=\"Model Kwargs\",\r\n            advanced=True,\r\n            info='Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}',\r\n        ),\r\n        DictInput(\r\n            name=\"custom_headers\",\r\n            display_name=\"Custom Headers\",\r\n            advanced=True,\r\n            info='Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}',\r\n        ),\r\n        IntInput(\r\n            name=\"top_k\",\r\n            display_name=\"Top K\",\r\n            info=\"Non-standard parameter. The number of highest probability tokens to keep for filtering.\",\r\n            value=50,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"frequency_penalty\",\r\n            display_name=\"Frequency Penalty\",\r\n            info=\"Standard parameter that decreases the model's likelihood to repeat the same line.\",\r\n            value=0.0,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"json_mode\",\r\n            display_name=\"JSON Mode\",\r\n            advanced=True,\r\n            info=\"If True, it will output JSON regardless of passing a schema.\",\r\n        ),\r\n        IntInput(\r\n            name=\"seed\",\r\n            display_name=\"Seed\",\r\n            info=\"The seed controls the reproducibility of the job.\",\r\n            advanced=True,\r\n            value=1,\r\n        ),\r\n    ]\r\n\r\n    def get_models(self) -> list[str]:\r\n        if not self.api_key:\r\n            return DEEPSEEK_MODELS\r\n\r\n        api_base = self.api_base or \"https://api.deepseek.com\"\r\n        url = f\"{api_base.strip('/')}/models\"\r\n        \r\n        try:\r\n            api_key_value = self.api_key.get_secret_value() if isinstance(self.api_key, SecretStr) else self.api_key\r\n            headers = {\"Authorization\": f\"Bearer {api_key_value}\", \"Accept\": \"application/json\"}\r\n            response = requests.get(url, headers=headers, timeout=5)\r\n            response.raise_for_status()\r\n            model_list = response.json()\r\n            fetched_models = [model[\"id\"] for model in model_list.get(\"data\", [])]\r\n            return sorted(list(set(fetched_models + DEEPSEEK_MODELS)))\r\n        except requests.RequestException as e:\r\n            self.status = f\"Error fetching models: {e}\"\r\n            return DEEPSEEK_MODELS\r\n\r\n    @override\r\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\r\n        if field_name in {\"api_key\", \"api_base\", \"model_name\"}:\r\n            models = self.get_models()\r\n            build_config[\"model_name\"][\"options\"] = models\r\n        return build_config\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        try:\r\n            from langchain_openai import ChatOpenAI\r\n        except ImportError as e:\r\n            msg = \"langchain-openai not installed. Please install with `pip install langchain-openai`\"\r\n            raise ImportError(msg) from e\r\n\r\n        api_key_value = None\r\n        if self.api_key:\r\n            if isinstance(self.api_key, SecretStr):\r\n                api_key_value = self.api_key.get_secret_value()\r\n            else:\r\n                api_key_value = self.api_key\r\n        \r\n        model_kwargs = self.model_kwargs or {}\r\n        \r\n        if self.top_p is not None:\r\n            model_kwargs[\"top_p\"] = self.top_p\r\n        if self.frequency_penalty is not None:\r\n            model_kwargs[\"frequency_penalty\"] = self.frequency_penalty\r\n            \r\n        extra_body = model_kwargs.get(\"extra_body\", {})\r\n        if self.top_k is not None:\r\n            extra_body[\"top_k\"] = self.top_k\r\n            \r\n        if extra_body:\r\n            model_kwargs[\"extra_body\"] = extra_body\r\n\r\n        # <--- 修正部分：根据开关状态设置 tool_choice (CORRECTED PART: set tool_choice based on the switch state) --->\r\n        if self.tool_model_enabled:\r\n            model_kwargs[\"tool_choice\"] = \"auto\"\r\n        # <--- 修正部分结束 --->\r\n            \r\n        output = ChatOpenAI(\r\n            model=self.model_name,\r\n            temperature=self.temperature if self.temperature is not None else 0.1,\r\n            max_tokens=self.max_tokens if self.max_tokens else None,\r\n            model_kwargs=model_kwargs,\r\n            base_url=self.api_base,\r\n            api_key=api_key_value,\r\n            streaming=self.stream,\r\n            seed=self.seed,\r\n        )\r\n\r\n        if self.custom_headers:\r\n            output = output.bind(extra_headers=self.custom_headers)\r\n\r\n        if self.json_mode:\r\n            output = output.bind(response_format={\"type\": \"json_object\"})\r\n\r\n        return output\r\n\r\n    def _get_exception_message(self, e: Exception):\r\n        \"\"\"Get message from DeepSeek API exception.\"\"\"\r\n        try:\r\n            from openai import BadRequestError\r\n\r\n            if isinstance(e, BadRequestError):\r\n                message = e.body.get(\"message\")\r\n                if message:\r\n                    return message\r\n        except ImportError:\r\n            pass\r\n        return str(e)"
              },
              "custom_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Custom Headers",
                "dynamic": false,
                "info": "Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "custom_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "X-Failover-Enabled": "true"
                }
              },
              "frequency_penalty": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Frequency Penalty",
                "dynamic": false,
                "info": "Standard parameter that decreases the model's likelihood to repeat the same line.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "frequency_penalty",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "Maximum number of tokens to generate. Set to 0 for unlimited.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "DeepSeek model to use. You can also type a custom model name.",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "deepseek-chat",
                  "deepseek-coder",
                  "DeepSeek-R1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "When enabled, sets tool_choice to 'auto', allowing the model to use connected tools.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Non-standard parameter. The number of highest probability tokens to keep for filtering.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 50
              },
              "top_p": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Top P",
                "dynamic": false,
                "info": "Controls diversity via nucleus sampling. This is a standard parameter.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "top_p",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.11
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "DeepSeekModelComponent"
        },
        "dragging": false,
        "id": "DeepSeekModelComponent-dM0pr",
        "measured": {
          "height": 749,
          "width": 320
        },
        "position": {
          "x": 4559.3073960473785,
          "y": 829.8820931180588
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DeepSeekModelComponent-V718b",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using DeepSeek LLMs.",
            "display_name": "DeepSeek",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "api_base",
              "api_key",
              "model_name",
              "tool_model_enabled",
              "temperature",
              "top_p",
              "max_tokens",
              "model_kwargs",
              "custom_headers",
              "top_k",
              "frequency_penalty",
              "json_mode",
              "seed"
            ],
            "frozen": false,
            "icon": "DeepSeek",
            "legacy": false,
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "API Base",
                "dynamic": false,
                "info": "Base URL for API requests. Defaults to https://api.deepseek.com",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://ai.gitee.com/v1"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "The DeepSeek API Key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "LV41QCCDGLTQLUUUBAM8KXZKCQOS4ZTUTQDGH461"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import requests\r\nfrom pydantic.v1 import SecretStr\r\nfrom typing_extensions import override\r\n\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import (\r\n    BoolInput,\r\n    DictInput,\r\n    DropdownInput,\r\n    IntInput,\r\n    SecretStrInput,\r\n    SliderInput,\r\n    StrInput,\r\n)\r\n\r\nDEEPSEEK_MODELS = [\"deepseek-chat\", \"deepseek-coder\", \"DeepSeek-R1\"]\r\n\r\n\r\nclass DeepSeekModelComponent(LCModelComponent):\r\n    display_name = \"DeepSeek\"\r\n    description = \"Generate text using DeepSeek LLMs.\"\r\n    icon = \"DeepSeek\"\r\n\r\n    inputs = [\r\n        *LCModelComponent._base_inputs,\r\n        StrInput(\r\n            name=\"api_base\",\r\n            display_name=\"API Base\",\r\n            advanced=False,\r\n            info=\"Base URL for API requests. Defaults to https://api.deepseek.com\",\r\n            value=\"https://api.deepseek.com\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"The DeepSeek API Key\",\r\n            advanced=False,\r\n            required=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            info=\"DeepSeek model to use. You can also type a custom model name.\",\r\n            options=DEEPSEEK_MODELS,\r\n            value=\"deepseek-chat\",\r\n            refresh_button=True,\r\n        ),\r\n        # <--- 修正部分：改回布尔开关 (CORRECTED PART: Changed back to a boolean switch) --->\r\n        BoolInput(\r\n            name=\"tool_model_enabled\",\r\n            display_name=\"Tool Model Enabled\",\r\n            info=\"When enabled, sets tool_choice to 'auto', allowing the model to use connected tools.\",\r\n            value=False, # 默认为关闭\r\n            advanced=False,\r\n        ),\r\n        # <--- 修正部分结束 --->\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            info=\"Controls randomness in responses.\",\r\n            value=0.6,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        SliderInput(\r\n            name=\"top_p\",\r\n            display_name=\"Top P\",\r\n            info=\"Controls diversity via nucleus sampling. This is a standard parameter.\",\r\n            value=0.7,\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        IntInput(\r\n            name=\"max_tokens\",\r\n            display_name=\"Max Tokens\",\r\n            advanced=True,\r\n            info=\"Maximum number of tokens to generate. Set to 0 for unlimited.\",\r\n            value=8192,\r\n            range_spec=RangeSpec(min=0, max=128000),\r\n        ),\r\n        DictInput(\r\n            name=\"model_kwargs\",\r\n            display_name=\"Model Kwargs\",\r\n            advanced=True,\r\n            info='Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}',\r\n        ),\r\n        DictInput(\r\n            name=\"custom_headers\",\r\n            display_name=\"Custom Headers\",\r\n            advanced=True,\r\n            info='Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}',\r\n        ),\r\n        IntInput(\r\n            name=\"top_k\",\r\n            display_name=\"Top K\",\r\n            info=\"Non-standard parameter. The number of highest probability tokens to keep for filtering.\",\r\n            value=50,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"frequency_penalty\",\r\n            display_name=\"Frequency Penalty\",\r\n            info=\"Standard parameter that decreases the model's likelihood to repeat the same line.\",\r\n            value=0.0,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"json_mode\",\r\n            display_name=\"JSON Mode\",\r\n            advanced=True,\r\n            info=\"If True, it will output JSON regardless of passing a schema.\",\r\n        ),\r\n        IntInput(\r\n            name=\"seed\",\r\n            display_name=\"Seed\",\r\n            info=\"The seed controls the reproducibility of the job.\",\r\n            advanced=True,\r\n            value=1,\r\n        ),\r\n    ]\r\n\r\n    def get_models(self) -> list[str]:\r\n        if not self.api_key:\r\n            return DEEPSEEK_MODELS\r\n\r\n        api_base = self.api_base or \"https://api.deepseek.com\"\r\n        url = f\"{api_base.strip('/')}/models\"\r\n        \r\n        try:\r\n            api_key_value = self.api_key.get_secret_value() if isinstance(self.api_key, SecretStr) else self.api_key\r\n            headers = {\"Authorization\": f\"Bearer {api_key_value}\", \"Accept\": \"application/json\"}\r\n            response = requests.get(url, headers=headers, timeout=5)\r\n            response.raise_for_status()\r\n            model_list = response.json()\r\n            fetched_models = [model[\"id\"] for model in model_list.get(\"data\", [])]\r\n            return sorted(list(set(fetched_models + DEEPSEEK_MODELS)))\r\n        except requests.RequestException as e:\r\n            self.status = f\"Error fetching models: {e}\"\r\n            return DEEPSEEK_MODELS\r\n\r\n    @override\r\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\r\n        if field_name in {\"api_key\", \"api_base\", \"model_name\"}:\r\n            models = self.get_models()\r\n            build_config[\"model_name\"][\"options\"] = models\r\n        return build_config\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        try:\r\n            from langchain_openai import ChatOpenAI\r\n        except ImportError as e:\r\n            msg = \"langchain-openai not installed. Please install with `pip install langchain-openai`\"\r\n            raise ImportError(msg) from e\r\n\r\n        api_key_value = None\r\n        if self.api_key:\r\n            if isinstance(self.api_key, SecretStr):\r\n                api_key_value = self.api_key.get_secret_value()\r\n            else:\r\n                api_key_value = self.api_key\r\n        \r\n        model_kwargs = self.model_kwargs or {}\r\n        \r\n        if self.top_p is not None:\r\n            model_kwargs[\"top_p\"] = self.top_p\r\n        if self.frequency_penalty is not None:\r\n            model_kwargs[\"frequency_penalty\"] = self.frequency_penalty\r\n            \r\n        extra_body = model_kwargs.get(\"extra_body\", {})\r\n        if self.top_k is not None:\r\n            extra_body[\"top_k\"] = self.top_k\r\n            \r\n        if extra_body:\r\n            model_kwargs[\"extra_body\"] = extra_body\r\n\r\n        # <--- 修正部分：根据开关状态设置 tool_choice (CORRECTED PART: set tool_choice based on the switch state) --->\r\n        if self.tool_model_enabled:\r\n            model_kwargs[\"tool_choice\"] = \"auto\"\r\n        # <--- 修正部分结束 --->\r\n            \r\n        output = ChatOpenAI(\r\n            model=self.model_name,\r\n            temperature=self.temperature if self.temperature is not None else 0.1,\r\n            max_tokens=self.max_tokens if self.max_tokens else None,\r\n            model_kwargs=model_kwargs,\r\n            base_url=self.api_base,\r\n            api_key=api_key_value,\r\n            streaming=self.stream,\r\n            seed=self.seed,\r\n        )\r\n\r\n        if self.custom_headers:\r\n            output = output.bind(extra_headers=self.custom_headers)\r\n\r\n        if self.json_mode:\r\n            output = output.bind(response_format={\"type\": \"json_object\"})\r\n\r\n        return output\r\n\r\n    def _get_exception_message(self, e: Exception):\r\n        \"\"\"Get message from DeepSeek API exception.\"\"\"\r\n        try:\r\n            from openai import BadRequestError\r\n\r\n            if isinstance(e, BadRequestError):\r\n                message = e.body.get(\"message\")\r\n                if message:\r\n                    return message\r\n        except ImportError:\r\n            pass\r\n        return str(e)"
              },
              "custom_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Custom Headers",
                "dynamic": false,
                "info": "Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "custom_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "X-Failover-Enabled": "true"
                }
              },
              "frequency_penalty": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Frequency Penalty",
                "dynamic": false,
                "info": "Standard parameter that decreases the model's likelihood to repeat the same line.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "frequency_penalty",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "Maximum number of tokens to generate. Set to 0 for unlimited.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "DeepSeek model to use. You can also type a custom model name.",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "deepseek-chat",
                  "deepseek-coder",
                  "DeepSeek-R1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "你是一位顶级的开源项目分析师。你的任务是基于给定的定量数据和定性信息，生成一份专业、深入、图文并茂的分析报告。你必须严谨、客观，在不确定时，要主动使用工具进行核实。你的最终产出是一份可以直接发布的Markdown中文报告。"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "When enabled, sets tool_choice to 'auto', allowing the model to use connected tools.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Non-standard parameter. The number of highest probability tokens to keep for filtering.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 50
              },
              "top_p": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Top P",
                "dynamic": false,
                "info": "Controls diversity via nucleus sampling. This is a standard parameter.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "top_p",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.11
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "DeepSeekModelComponent"
        },
        "dragging": false,
        "id": "DeepSeekModelComponent-V718b",
        "measured": {
          "height": 749,
          "width": 320
        },
        "position": {
          "x": 4915.055859960486,
          "y": 561.9992136654174
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DeepSeekModelComponent-0Cvgn",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using DeepSeek LLMs.",
            "display_name": "DeepSeek",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "api_base",
              "api_key",
              "model_name",
              "tool_model_enabled",
              "temperature",
              "top_p",
              "max_tokens",
              "model_kwargs",
              "custom_headers",
              "top_k",
              "frequency_penalty",
              "json_mode",
              "seed"
            ],
            "frozen": false,
            "icon": "DeepSeek",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "API Base",
                "dynamic": false,
                "info": "Base URL for API requests. Defaults to https://api.deepseek.com",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://ai.gitee.com/v1"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "The DeepSeek API Key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "LV41QCCDGLTQLUUUBAM8KXZKCQOS4ZTUTQDGH461"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import requests\r\nfrom pydantic.v1 import SecretStr\r\nfrom typing_extensions import override\r\n\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import (\r\n    BoolInput,\r\n    DictInput,\r\n    DropdownInput,\r\n    IntInput,\r\n    SecretStrInput,\r\n    SliderInput,\r\n    StrInput,\r\n)\r\n\r\nDEEPSEEK_MODELS = [\"deepseek-chat\", \"deepseek-coder\", \"DeepSeek-R1\"]\r\n\r\n\r\nclass DeepSeekModelComponent(LCModelComponent):\r\n    display_name = \"DeepSeek\"\r\n    description = \"Generate text using DeepSeek LLMs.\"\r\n    icon = \"DeepSeek\"\r\n\r\n    inputs = [\r\n        *LCModelComponent._base_inputs,\r\n        StrInput(\r\n            name=\"api_base\",\r\n            display_name=\"API Base\",\r\n            advanced=False,\r\n            info=\"Base URL for API requests. Defaults to https://api.deepseek.com\",\r\n            value=\"https://api.deepseek.com\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"The DeepSeek API Key\",\r\n            advanced=False,\r\n            required=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            info=\"DeepSeek model to use. You can also type a custom model name.\",\r\n            options=DEEPSEEK_MODELS,\r\n            value=\"deepseek-chat\",\r\n            refresh_button=True,\r\n        ),\r\n        # <--- 修正部分：改回布尔开关 (CORRECTED PART: Changed back to a boolean switch) --->\r\n        BoolInput(\r\n            name=\"tool_model_enabled\",\r\n            display_name=\"Tool Model Enabled\",\r\n            info=\"When enabled, sets tool_choice to 'auto', allowing the model to use connected tools.\",\r\n            value=False, # 默认为关闭\r\n            advanced=False,\r\n        ),\r\n        # <--- 修正部分结束 --->\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            info=\"Controls randomness in responses.\",\r\n            value=0.6,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        SliderInput(\r\n            name=\"top_p\",\r\n            display_name=\"Top P\",\r\n            info=\"Controls diversity via nucleus sampling. This is a standard parameter.\",\r\n            value=0.7,\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=False,\r\n        ),\r\n        IntInput(\r\n            name=\"max_tokens\",\r\n            display_name=\"Max Tokens\",\r\n            advanced=True,\r\n            info=\"Maximum number of tokens to generate. Set to 0 for unlimited.\",\r\n            value=8192,\r\n            range_spec=RangeSpec(min=0, max=128000),\r\n        ),\r\n        DictInput(\r\n            name=\"model_kwargs\",\r\n            display_name=\"Model Kwargs\",\r\n            advanced=True,\r\n            info='Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}',\r\n        ),\r\n        DictInput(\r\n            name=\"custom_headers\",\r\n            display_name=\"Custom Headers\",\r\n            advanced=True,\r\n            info='Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}',\r\n        ),\r\n        IntInput(\r\n            name=\"top_k\",\r\n            display_name=\"Top K\",\r\n            info=\"Non-standard parameter. The number of highest probability tokens to keep for filtering.\",\r\n            value=50,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"frequency_penalty\",\r\n            display_name=\"Frequency Penalty\",\r\n            info=\"Standard parameter that decreases the model's likelihood to repeat the same line.\",\r\n            value=0.0,\r\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"json_mode\",\r\n            display_name=\"JSON Mode\",\r\n            advanced=True,\r\n            info=\"If True, it will output JSON regardless of passing a schema.\",\r\n        ),\r\n        IntInput(\r\n            name=\"seed\",\r\n            display_name=\"Seed\",\r\n            info=\"The seed controls the reproducibility of the job.\",\r\n            advanced=True,\r\n            value=1,\r\n        ),\r\n    ]\r\n\r\n    def get_models(self) -> list[str]:\r\n        if not self.api_key:\r\n            return DEEPSEEK_MODELS\r\n\r\n        api_base = self.api_base or \"https://api.deepseek.com\"\r\n        url = f\"{api_base.strip('/')}/models\"\r\n        \r\n        try:\r\n            api_key_value = self.api_key.get_secret_value() if isinstance(self.api_key, SecretStr) else self.api_key\r\n            headers = {\"Authorization\": f\"Bearer {api_key_value}\", \"Accept\": \"application/json\"}\r\n            response = requests.get(url, headers=headers, timeout=5)\r\n            response.raise_for_status()\r\n            model_list = response.json()\r\n            fetched_models = [model[\"id\"] for model in model_list.get(\"data\", [])]\r\n            return sorted(list(set(fetched_models + DEEPSEEK_MODELS)))\r\n        except requests.RequestException as e:\r\n            self.status = f\"Error fetching models: {e}\"\r\n            return DEEPSEEK_MODELS\r\n\r\n    @override\r\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\r\n        if field_name in {\"api_key\", \"api_base\", \"model_name\"}:\r\n            models = self.get_models()\r\n            build_config[\"model_name\"][\"options\"] = models\r\n        return build_config\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        try:\r\n            from langchain_openai import ChatOpenAI\r\n        except ImportError as e:\r\n            msg = \"langchain-openai not installed. Please install with `pip install langchain-openai`\"\r\n            raise ImportError(msg) from e\r\n\r\n        api_key_value = None\r\n        if self.api_key:\r\n            if isinstance(self.api_key, SecretStr):\r\n                api_key_value = self.api_key.get_secret_value()\r\n            else:\r\n                api_key_value = self.api_key\r\n        \r\n        model_kwargs = self.model_kwargs or {}\r\n        \r\n        if self.top_p is not None:\r\n            model_kwargs[\"top_p\"] = self.top_p\r\n        if self.frequency_penalty is not None:\r\n            model_kwargs[\"frequency_penalty\"] = self.frequency_penalty\r\n            \r\n        extra_body = model_kwargs.get(\"extra_body\", {})\r\n        if self.top_k is not None:\r\n            extra_body[\"top_k\"] = self.top_k\r\n            \r\n        if extra_body:\r\n            model_kwargs[\"extra_body\"] = extra_body\r\n\r\n        # <--- 修正部分：根据开关状态设置 tool_choice (CORRECTED PART: set tool_choice based on the switch state) --->\r\n        if self.tool_model_enabled:\r\n            model_kwargs[\"tool_choice\"] = \"auto\"\r\n        # <--- 修正部分结束 --->\r\n            \r\n        output = ChatOpenAI(\r\n            model=self.model_name,\r\n            temperature=self.temperature if self.temperature is not None else 0.1,\r\n            max_tokens=self.max_tokens if self.max_tokens else None,\r\n            model_kwargs=model_kwargs,\r\n            base_url=self.api_base,\r\n            api_key=api_key_value,\r\n            streaming=self.stream,\r\n            seed=self.seed,\r\n        )\r\n\r\n        if self.custom_headers:\r\n            output = output.bind(extra_headers=self.custom_headers)\r\n\r\n        if self.json_mode:\r\n            output = output.bind(response_format={\"type\": \"json_object\"})\r\n\r\n        return output\r\n\r\n    def _get_exception_message(self, e: Exception):\r\n        \"\"\"Get message from DeepSeek API exception.\"\"\"\r\n        try:\r\n            from openai import BadRequestError\r\n\r\n            if isinstance(e, BadRequestError):\r\n                message = e.body.get(\"message\")\r\n                if message:\r\n                    return message\r\n        except ImportError:\r\n            pass\r\n        return str(e)"
              },
              "custom_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Custom Headers",
                "dynamic": false,
                "info": "Custom headers to send with the request. E.g., {\"X-Failover-Enabled\": \"true\"}",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "custom_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "X-Failover-Enabled": "true"
                }
              },
              "frequency_penalty": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Frequency Penalty",
                "dynamic": false,
                "info": "Standard parameter that decreases the model's likelihood to repeat the same line.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "frequency_penalty",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "Maximum number of tokens to generate. Set to 0 for unlimited.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model. E.g., {\"extra_body\": {\"top_k\": 50}}",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "DeepSeek model to use. You can also type a custom model name.",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "deepseek-chat",
                  "deepseek-coder",
                  "DeepSeek-R1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "When enabled, sets tool_choice to 'auto', allowing the model to use connected tools.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Non-standard parameter. The number of highest probability tokens to keep for filtering.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 50
              },
              "top_p": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Top P",
                "dynamic": false,
                "info": "Controls diversity via nucleus sampling. This is a standard parameter.",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "top_p",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.11
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "DeepSeekModelComponent"
        },
        "dragging": false,
        "id": "DeepSeekModelComponent-0Cvgn",
        "measured": {
          "height": 749,
          "width": 320
        },
        "position": {
          "x": 5380.1005386902725,
          "y": 660.5801133039897
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-gHJAA",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-gHJAA",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 1105.0714956141287,
          "y": 1985.7153049683495
        },
        "selected": true,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -429.76736524093985,
      "y": -235.39620215539605,
      "zoom": 0.35363322060918595
    }
  },
  "description": "A simple but powerful starter agent.",
  "endpoint_name": null,
  "id": "00b8048d-0f62-44ab-a9fd-d4ee0e7f32e7",
  "is_component": false,
  "last_tested_version": "1.4.3",
  "name": "Ospp Agent DeepSeek",
  "tags": [
    "assistants",
    "agents"
  ]
}